20/12/10 15:36:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/12/10 15:36:57 INFO SecurityManager: Changing view acls to: bsuconn
20/12/10 15:36:57 INFO SecurityManager: Changing modify acls to: bsuconn
20/12/10 15:36:57 INFO SecurityManager: Changing view acls groups to: 
20/12/10 15:36:57 INFO SecurityManager: Changing modify acls groups to: 
20/12/10 15:36:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(bsuconn); groups with view permissions: Set(); users  with modify permissions: Set(bsuconn); groups with modify permissions: Set()
20/12/10 15:36:58 INFO SparkContext: Running Spark version 3.0.1
20/12/10 15:36:58 INFO ResourceUtils: ==============================================================
20/12/10 15:36:58 INFO ResourceUtils: Resources for spark.driver:

20/12/10 15:36:58 INFO ResourceUtils: ==============================================================
20/12/10 15:36:58 INFO SparkContext: Submitted application: Spark DARIMA App
20/12/10 15:36:58 INFO SecurityManager: Changing view acls to: bsuconn
20/12/10 15:36:58 INFO SecurityManager: Changing modify acls to: bsuconn
20/12/10 15:36:58 INFO SecurityManager: Changing view acls groups to: 
20/12/10 15:36:58 INFO SecurityManager: Changing modify acls groups to: 
20/12/10 15:36:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(bsuconn); groups with view permissions: Set(); users  with modify permissions: Set(bsuconn); groups with modify permissions: Set()
20/12/10 15:36:59 INFO Utils: Successfully started service 'sparkDriver' on port 40411.
20/12/10 15:36:59 INFO SparkEnv: Registering MapOutputTracker
20/12/10 15:36:59 INFO SparkEnv: Registering BlockManagerMaster
20/12/10 15:36:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/12/10 15:36:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/12/10 15:36:59 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
20/12/10 15:36:59 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1cc0c117-2246-4469-9640-f6c7ea859be9
20/12/10 15:36:59 INFO MemoryStore: MemoryStore started with capacity 5.8 GiB
20/12/10 15:36:59 INFO SparkEnv: Registering OutputCommitCoordinator
20/12/10 15:36:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/12/10 15:36:59 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.9:4040
20/12/10 15:37:00 INFO RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
20/12/10 15:37:00 INFO Client: Requesting a new application from cluster with 1 NodeManagers
20/12/10 15:37:01 INFO Configuration: resource-types.xml not found
20/12/10 15:37:01 INFO ResourceUtils: Unable to find 'resource-types.xml'.
20/12/10 15:37:01 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
20/12/10 15:37:01 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/12/10 15:37:01 INFO Client: Setting up container launch context for our AM
20/12/10 15:37:01 INFO Client: Setting up the launch environment for our AM container
20/12/10 15:37:01 INFO Client: Preparing resources for our AM container
20/12/10 15:37:01 WARN Client: Failed to cleanup staging dir hdfs://localhost:9000/user/bsuconn/.sparkStaging/application_1607632608624_0001
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/bsuconn/.sparkStaging/application_1607632608624_0001. Name node is in safe mode.
The reported blocks 37 has reached the threshold 0.9990 of total blocks 37. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 8 seconds. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1463)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3084)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1114)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:705)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1608)
	at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:952)
	at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:949)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:959)
	at org.apache.spark.deploy.yarn.Client.cleanupStagingDirInternal$1(Client.scala:226)
	at org.apache.spark.deploy.yarn.Client.cleanupStagingDir(Client.scala:235)
	at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:209)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:60)
	at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:201)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:555)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:238)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot delete /user/bsuconn/.sparkStaging/application_1607632608624_0001. Name node is in safe mode.
The reported blocks 37 has reached the threshold 0.9990 of total blocks 37. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 8 seconds. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1463)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3084)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1114)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:705)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.delete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.delete(ClientNamenodeProtocolTranslatorPB.java:637)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy20.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1606)
	... 22 more
20/12/10 15:37:01 ERROR SparkContext: Error initializing SparkContext.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /user/bsuconn/.sparkStaging/application_1607632608624_0001. Name node is in safe mode.
The reported blocks 37 has reached the threshold 0.9990 of total blocks 37. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 8 seconds. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1463)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3232)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1145)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:720)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2426)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2400)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1324)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1321)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1338)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1313)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2275)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:674)
	at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:441)
	at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:876)
	at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:196)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:60)
	at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:201)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:555)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:238)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create directory /user/bsuconn/.sparkStaging/application_1607632608624_0001. Name node is in safe mode.
The reported blocks 37 has reached the threshold 0.9990 of total blocks 37. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 8 seconds. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1463)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3232)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1145)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:720)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:656)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy20.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2424)
	... 26 more
20/12/10 15:37:01 INFO SparkUI: Stopped Spark web UI at http://192.168.1.9:4040
20/12/10 15:37:01 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!
20/12/10 15:37:01 INFO YarnClientSchedulerBackend: Shutting down all executors
20/12/10 15:37:01 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
20/12/10 15:37:01 INFO YarnClientSchedulerBackend: YARN client scheduler backend Stopped
20/12/10 15:37:01 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/12/10 15:37:01 INFO MemoryStore: MemoryStore cleared
20/12/10 15:37:01 INFO BlockManager: BlockManager stopped
20/12/10 15:37:01 INFO BlockManagerMaster: BlockManagerMaster stopped
20/12/10 15:37:01 WARN MetricsSystem: Stopping a MetricsSystem that is not running
20/12/10 15:37:01 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/12/10 15:37:01 INFO SparkContext: Successfully stopped SparkContext
20/12/10 15:37:01 INFO ShutdownHookManager: Shutdown hook called
20/12/10 15:37:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-49bbe505-2464-42f3-af41-021c043d07f5
20/12/10 15:37:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-878dc3ef-ecaa-46ba-9c58-628316951cc9
20/12/10 15:37:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/12/10 15:37:03 INFO SecurityManager: Changing view acls to: bsuconn
20/12/10 15:37:03 INFO SecurityManager: Changing modify acls to: bsuconn
20/12/10 15:37:03 INFO SecurityManager: Changing view acls groups to: 
20/12/10 15:37:03 INFO SecurityManager: Changing modify acls groups to: 
20/12/10 15:37:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(bsuconn); groups with view permissions: Set(); users  with modify permissions: Set(bsuconn); groups with modify permissions: Set()
20/12/10 15:37:04 INFO SparkContext: Running Spark version 3.0.1
20/12/10 15:37:04 INFO ResourceUtils: ==============================================================
20/12/10 15:37:04 INFO ResourceUtils: Resources for spark.driver:

20/12/10 15:37:04 INFO ResourceUtils: ==============================================================
20/12/10 15:37:04 INFO SparkContext: Submitted application: Spark DARIMA App
20/12/10 15:37:04 INFO SecurityManager: Changing view acls to: bsuconn
20/12/10 15:37:04 INFO SecurityManager: Changing modify acls to: bsuconn
20/12/10 15:37:04 INFO SecurityManager: Changing view acls groups to: 
20/12/10 15:37:04 INFO SecurityManager: Changing modify acls groups to: 
20/12/10 15:37:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(bsuconn); groups with view permissions: Set(); users  with modify permissions: Set(bsuconn); groups with modify permissions: Set()
20/12/10 15:37:05 INFO Utils: Successfully started service 'sparkDriver' on port 42335.
20/12/10 15:37:05 INFO SparkEnv: Registering MapOutputTracker
20/12/10 15:37:05 INFO SparkEnv: Registering BlockManagerMaster
20/12/10 15:37:05 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/12/10 15:37:05 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/12/10 15:37:05 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
20/12/10 15:37:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-507823ae-c658-4dc4-b13d-1ec506d15f29
20/12/10 15:37:05 INFO MemoryStore: MemoryStore started with capacity 5.8 GiB
20/12/10 15:37:05 INFO SparkEnv: Registering OutputCommitCoordinator
20/12/10 15:37:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/12/10 15:37:05 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.9:4040
20/12/10 15:37:06 INFO RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
20/12/10 15:37:06 INFO Client: Requesting a new application from cluster with 1 NodeManagers
20/12/10 15:37:06 INFO Configuration: resource-types.xml not found
20/12/10 15:37:06 INFO ResourceUtils: Unable to find 'resource-types.xml'.
20/12/10 15:37:06 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
20/12/10 15:37:06 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/12/10 15:37:06 INFO Client: Setting up container launch context for our AM
20/12/10 15:37:06 INFO Client: Setting up the launch environment for our AM container
20/12/10 15:37:06 INFO Client: Preparing resources for our AM container
20/12/10 15:37:06 WARN Client: Failed to cleanup staging dir hdfs://localhost:9000/user/bsuconn/.sparkStaging/application_1607632608624_0002
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/bsuconn/.sparkStaging/application_1607632608624_0002. Name node is in safe mode.
The reported blocks 37 has reached the threshold 0.9990 of total blocks 37. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1463)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3084)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1114)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:705)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1608)
	at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:952)
	at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:949)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:959)
	at org.apache.spark.deploy.yarn.Client.cleanupStagingDirInternal$1(Client.scala:226)
	at org.apache.spark.deploy.yarn.Client.cleanupStagingDir(Client.scala:235)
	at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:209)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:60)
	at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:201)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:555)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:238)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot delete /user/bsuconn/.sparkStaging/application_1607632608624_0002. Name node is in safe mode.
The reported blocks 37 has reached the threshold 0.9990 of total blocks 37. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1463)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3084)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1114)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:705)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.delete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.delete(ClientNamenodeProtocolTranslatorPB.java:637)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy20.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1606)
	... 22 more
20/12/10 15:37:06 ERROR SparkContext: Error initializing SparkContext.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /user/bsuconn/.sparkStaging/application_1607632608624_0002. Name node is in safe mode.
The reported blocks 37 has reached the threshold 0.9990 of total blocks 37. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1463)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3232)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1145)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:720)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2426)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2400)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1324)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1321)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1338)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1313)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2275)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:674)
	at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:441)
	at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:876)
	at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:196)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:60)
	at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:201)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:555)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:238)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create directory /user/bsuconn/.sparkStaging/application_1607632608624_0002. Name node is in safe mode.
The reported blocks 37 has reached the threshold 0.9990 of total blocks 37. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1463)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3232)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1145)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:720)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:656)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy20.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2424)
	... 26 more
20/12/10 15:37:06 INFO SparkUI: Stopped Spark web UI at http://192.168.1.9:4040
20/12/10 15:37:06 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!
20/12/10 15:37:06 INFO YarnClientSchedulerBackend: Shutting down all executors
20/12/10 15:37:06 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
20/12/10 15:37:06 INFO YarnClientSchedulerBackend: YARN client scheduler backend Stopped
20/12/10 15:37:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/12/10 15:37:07 INFO MemoryStore: MemoryStore cleared
20/12/10 15:37:07 INFO BlockManager: BlockManager stopped
20/12/10 15:37:07 INFO BlockManagerMaster: BlockManagerMaster stopped
20/12/10 15:37:07 WARN MetricsSystem: Stopping a MetricsSystem that is not running
20/12/10 15:37:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/12/10 15:37:07 INFO SparkContext: Successfully stopped SparkContext
20/12/10 15:37:07 INFO ShutdownHookManager: Shutdown hook called
20/12/10 15:37:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-ecee92e9-1684-4fd4-b472-dee8ab9dab79
20/12/10 15:37:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-8c85510f-9f62-4188-901c-a224adb7c9ec
20/12/10 15:37:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/12/10 15:37:09 INFO SecurityManager: Changing view acls to: bsuconn
20/12/10 15:37:09 INFO SecurityManager: Changing modify acls to: bsuconn
20/12/10 15:37:09 INFO SecurityManager: Changing view acls groups to: 
20/12/10 15:37:09 INFO SecurityManager: Changing modify acls groups to: 
20/12/10 15:37:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(bsuconn); groups with view permissions: Set(); users  with modify permissions: Set(bsuconn); groups with modify permissions: Set()
20/12/10 15:37:10 INFO SparkContext: Running Spark version 3.0.1
20/12/10 15:37:10 INFO ResourceUtils: ==============================================================
20/12/10 15:37:10 INFO ResourceUtils: Resources for spark.driver:

20/12/10 15:37:10 INFO ResourceUtils: ==============================================================
20/12/10 15:37:10 INFO SparkContext: Submitted application: Spark DARIMA App
20/12/10 15:37:10 INFO SecurityManager: Changing view acls to: bsuconn
20/12/10 15:37:10 INFO SecurityManager: Changing modify acls to: bsuconn
20/12/10 15:37:10 INFO SecurityManager: Changing view acls groups to: 
20/12/10 15:37:10 INFO SecurityManager: Changing modify acls groups to: 
20/12/10 15:37:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(bsuconn); groups with view permissions: Set(); users  with modify permissions: Set(bsuconn); groups with modify permissions: Set()
20/12/10 15:37:11 INFO Utils: Successfully started service 'sparkDriver' on port 45557.
20/12/10 15:37:11 INFO SparkEnv: Registering MapOutputTracker
20/12/10 15:37:11 INFO SparkEnv: Registering BlockManagerMaster
20/12/10 15:37:11 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/12/10 15:37:11 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/12/10 15:37:11 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
20/12/10 15:37:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9ac88472-b0f9-4e72-a014-ff5f72461b10
20/12/10 15:37:11 INFO MemoryStore: MemoryStore started with capacity 5.8 GiB
20/12/10 15:37:11 INFO SparkEnv: Registering OutputCommitCoordinator
20/12/10 15:37:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/12/10 15:37:11 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.9:4040
20/12/10 15:37:12 INFO RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
20/12/10 15:37:12 INFO Client: Requesting a new application from cluster with 1 NodeManagers
20/12/10 15:37:12 INFO Configuration: resource-types.xml not found
20/12/10 15:37:12 INFO ResourceUtils: Unable to find 'resource-types.xml'.
20/12/10 15:37:12 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
20/12/10 15:37:12 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/12/10 15:37:12 INFO Client: Setting up container launch context for our AM
20/12/10 15:37:12 INFO Client: Setting up the launch environment for our AM container
20/12/10 15:37:12 INFO Client: Preparing resources for our AM container
20/12/10 15:37:13 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
20/12/10 15:37:15 INFO Client: Uploading resource file:/tmp/spark-6b081aa8-4a38-489f-9ffe-eed10e409391/__spark_libs__13103226946622867152.zip -> hdfs://localhost:9000/user/bsuconn/.sparkStaging/application_1607632608624_0003/__spark_libs__13103226946622867152.zip
20/12/10 15:37:16 INFO Client: Uploading resource file:/home/bsuconn/spark/spark-3.0.1-bin-hadoop3.2/python/lib/pyspark.zip -> hdfs://localhost:9000/user/bsuconn/.sparkStaging/application_1607632608624_0003/pyspark.zip
20/12/10 15:37:16 INFO Client: Uploading resource file:/home/bsuconn/spark/spark-3.0.1-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip -> hdfs://localhost:9000/user/bsuconn/.sparkStaging/application_1607632608624_0003/py4j-0.10.9-src.zip
20/12/10 15:37:16 INFO Client: Uploading resource file:/tmp/spark-6b081aa8-4a38-489f-9ffe-eed10e409391/__spark_conf__10358754853217719412.zip -> hdfs://localhost:9000/user/bsuconn/.sparkStaging/application_1607632608624_0003/__spark_conf__.zip
20/12/10 15:37:16 INFO SecurityManager: Changing view acls to: bsuconn
20/12/10 15:37:16 INFO SecurityManager: Changing modify acls to: bsuconn
20/12/10 15:37:16 INFO SecurityManager: Changing view acls groups to: 
20/12/10 15:37:16 INFO SecurityManager: Changing modify acls groups to: 
20/12/10 15:37:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(bsuconn); groups with view permissions: Set(); users  with modify permissions: Set(bsuconn); groups with modify permissions: Set()
20/12/10 15:37:16 INFO Client: Submitting application application_1607632608624_0003 to ResourceManager
20/12/10 15:37:17 INFO YarnClientImpl: Submitted application application_1607632608624_0003
20/12/10 15:37:18 INFO Client: Application report for application_1607632608624_0003 (state: ACCEPTED)
20/12/10 15:37:18 INFO Client: 
	 client token: N/A
	 diagnostics: [Thu Dec 10 15:37:17 -0500 2020] Scheduler has assigned a container for AM, waiting for AM container to be launched
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1607632637075
	 final status: UNDEFINED
	 tracking URL: http://pop-os:8088/proxy/application_1607632608624_0003/
	 user: bsuconn
20/12/10 15:37:19 INFO Client: Application report for application_1607632608624_0003 (state: ACCEPTED)
20/12/10 15:37:20 INFO Client: Application report for application_1607632608624_0003 (state: ACCEPTED)
20/12/10 15:37:21 INFO Client: Application report for application_1607632608624_0003 (state: ACCEPTED)
20/12/10 15:37:22 INFO Client: Application report for application_1607632608624_0003 (state: ACCEPTED)
20/12/10 15:37:23 INFO Client: Application report for application_1607632608624_0003 (state: ACCEPTED)
20/12/10 15:37:24 INFO Client: Application report for application_1607632608624_0003 (state: ACCEPTED)
20/12/10 15:37:24 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> pop-os, PROXY_URI_BASES -> http://pop-os:8088/proxy/application_1607632608624_0003), /proxy/application_1607632608624_0003
20/12/10 15:37:25 INFO Client: Application report for application_1607632608624_0003 (state: RUNNING)
20/12/10 15:37:25 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 192.168.1.9
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1607632637075
	 final status: UNDEFINED
	 tracking URL: http://pop-os:8088/proxy/application_1607632608624_0003/
	 user: bsuconn
20/12/10 15:37:25 INFO YarnClientSchedulerBackend: Application application_1607632608624_0003 has started running.
20/12/10 15:37:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34905.
20/12/10 15:37:25 INFO NettyBlockTransferService: Server created on 192.168.1.9:34905
20/12/10 15:37:25 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/12/10 15:37:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.9, 34905, None)
20/12/10 15:37:25 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.9:34905 with 5.8 GiB RAM, BlockManagerId(driver, 192.168.1.9, 34905, None)
20/12/10 15:37:25 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.9, 34905, None)
20/12/10 15:37:25 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.1.9, 34905, None)
20/12/10 15:37:25 INFO ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
20/12/10 15:37:25 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
20/12/10 15:37:30 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
20/12/10 15:37:32 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.9:39108) with ID 1
20/12/10 15:37:32 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.9:34817 with 912.3 MiB RAM, BlockManagerId(1, 192.168.1.9, 34817, None)
20/12/10 15:37:33 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.9:39114) with ID 2
20/12/10 15:37:33 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.9:43683 with 912.3 MiB RAM, BlockManagerId(2, 192.168.1.9, 43683, None)
20/12/10 15:37:42 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)
20/12/10 15:37:42 INFO SharedState: loading hive config file: file:/home/bsuconn/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
20/12/10 15:37:42 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/bsuconn/Documents/Fall_2020/STAT_5825/Project/spark-warehouse').
20/12/10 15:37:42 INFO SharedState: Warehouse path is 'file:/home/bsuconn/Documents/Fall_2020/STAT_5825/Project/spark-warehouse'.
20/12/10 15:37:42 INFO ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
20/12/10 15:37:42 INFO ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
20/12/10 15:37:42 INFO ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
20/12/10 15:37:42 INFO ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
20/12/10 15:37:42 INFO ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
20/12/10 15:37:43 INFO SparkContext: Added file darima-master/bash/darima.zip at spark://192.168.1.9:45557/files/darima.zip with timestamp 1607632663133
20/12/10 15:37:43 INFO Utils: Copying /home/bsuconn/Documents/Fall_2020/STAT_5825/Project/darima-master/bash/darima.zip to /tmp/spark-6b081aa8-4a38-489f-9ffe-eed10e409391/userFiles-6604436f-6746-486a-b42f-87ca96b62dd2/darima.zip
20/12/10 15:37:45 INFO InMemoryFileIndex: It took 85 ms to list leaf files for 1 paths.
20/12/10 15:37:47 INFO InMemoryFileIndex: It took 14 ms to list leaf files for 1 paths.
20/12/10 15:37:48 INFO FileSourceStrategy: Pruning directories with: 
20/12/10 15:37:48 INFO FileSourceStrategy: Pushed Filters: 
20/12/10 15:37:48 INFO FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, t#1,traffic_volume#0)
20/12/10 15:37:48 INFO FileSourceStrategy: Output Data Schema: struct<traffic_volume: double, t: string>
20/12/10 15:37:49 INFO CodeGenerator: Code generated in 378.230003 ms
20/12/10 15:37:49 INFO CodeGenerator: Code generated in 39.471982 ms
20/12/10 15:37:49 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 177.4 KiB, free 5.8 GiB)
20/12/10 15:37:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 28.7 KiB, free 5.8 GiB)
20/12/10 15:37:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.1.9:34905 (size: 28.7 KiB, free: 5.8 GiB)
20/12/10 15:37:49 INFO SparkContext: Created broadcast 0 from count at NativeMethodAccessorImpl.java:0
20/12/10 15:37:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 15:37:50 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
20/12/10 15:37:50 INFO DAGScheduler: Registering RDD 3 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
20/12/10 15:37:50 INFO DAGScheduler: Got job 0 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 15:37:50 INFO DAGScheduler: Final stage: ResultStage 1 (count at NativeMethodAccessorImpl.java:0)
20/12/10 15:37:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
20/12/10 15:37:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
20/12/10 15:37:50 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 15:37:50 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 16.0 KiB, free 5.8 GiB)
20/12/10 15:37:50 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 5.8 GiB)
20/12/10 15:37:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.1.9:34905 (size: 8.0 KiB, free: 5.8 GiB)
20/12/10 15:37:50 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
20/12/10 15:37:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 15:37:50 INFO YarnScheduler: Adding task set 0.0 with 1 tasks
20/12/10 15:37:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.1.9, executor 2, partition 0, NODE_LOCAL, 7779 bytes)
20/12/10 15:37:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.1.9:43683 (size: 8.0 KiB, free: 912.3 MiB)
20/12/10 15:37:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.1.9:43683 (size: 28.7 KiB, free: 912.3 MiB)
20/12/10 15:37:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4113 ms on 192.168.1.9 (executor 2) (1/1)
20/12/10 15:37:54 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/12/10 15:37:54 INFO DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 4.293 s
20/12/10 15:37:54 INFO DAGScheduler: looking for newly runnable stages
20/12/10 15:37:54 INFO DAGScheduler: running: Set()
20/12/10 15:37:54 INFO DAGScheduler: waiting: Set(ResultStage 1)
20/12/10 15:37:54 INFO DAGScheduler: failed: Set()
20/12/10 15:37:54 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 15:37:54 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.1 KiB, free 5.8 GiB)
20/12/10 15:37:54 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 5.8 GiB)
20/12/10 15:37:54 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.1.9:34905 (size: 5.0 KiB, free: 5.8 GiB)
20/12/10 15:37:54 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1223
20/12/10 15:37:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 15:37:54 INFO YarnScheduler: Adding task set 1.0 with 1 tasks
20/12/10 15:37:54 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 192.168.1.9, executor 1, partition 0, NODE_LOCAL, 7336 bytes)
20/12/10 15:37:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.1.9:34817 (size: 5.0 KiB, free: 912.3 MiB)
20/12/10 15:37:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 192.168.1.9:39108
20/12/10 15:37:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 3134 ms on 192.168.1.9 (executor 1) (1/1)
20/12/10 15:37:57 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/12/10 15:37:57 INFO DAGScheduler: ResultStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 3.154 s
20/12/10 15:37:57 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
20/12/10 15:37:57 INFO YarnScheduler: Killing all running tasks in stage 1: Stage finished
20/12/10 15:37:57 INFO DAGScheduler: Job 0 finished: count at NativeMethodAccessorImpl.java:0, took 7.559786 s
20/12/10 15:37:59 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.1.9:34905 in memory (size: 8.0 KiB, free: 5.8 GiB)
20/12/10 15:37:59 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.1.9:43683 in memory (size: 8.0 KiB, free: 912.3 MiB)
20/12/10 15:37:59 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.1.9:34905 in memory (size: 5.0 KiB, free: 5.8 GiB)
20/12/10 15:37:59 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.1.9:34817 in memory (size: 5.0 KiB, free: 912.3 MiB)
20/12/10 15:37:59 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.1.9:34905 in memory (size: 28.7 KiB, free: 5.8 GiB)
20/12/10 15:37:59 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.1.9:43683 in memory (size: 28.7 KiB, free: 912.3 MiB)
20/12/10 15:38:00 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
20/12/10 15:38:01 INFO FileSourceStrategy: Pruning directories with: 
20/12/10 15:38:01 INFO FileSourceStrategy: Pushed Filters: 
20/12/10 15:38:01 INFO FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, t#1,traffic_volume#0)
20/12/10 15:38:01 INFO FileSourceStrategy: Output Data Schema: struct<traffic_volume: double, t: string>
20/12/10 15:38:01 INFO CodeGenerator: Code generated in 18.323161 ms
20/12/10 15:38:01 INFO CodeGenerator: Code generated in 11.203634 ms
20/12/10 15:38:01 INFO CodeGenerator: Code generated in 13.442762 ms
20/12/10 15:38:01 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 177.4 KiB, free 5.8 GiB)
20/12/10 15:38:01 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 28.7 KiB, free 5.8 GiB)
20/12/10 15:38:01 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.1.9:34905 (size: 28.7 KiB, free: 5.8 GiB)
20/12/10 15:38:01 INFO SparkContext: Created broadcast 3 from toPandas at /tmp/spark-6b081aa8-4a38-489f-9ffe-eed10e409391/userFiles-6604436f-6746-486a-b42f-87ca96b62dd2/darima.zip/darima/dlsa.py:22
20/12/10 15:38:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 15:38:01 INFO SparkContext: Starting job: toPandas at /tmp/spark-6b081aa8-4a38-489f-9ffe-eed10e409391/userFiles-6604436f-6746-486a-b42f-87ca96b62dd2/darima.zip/darima/dlsa.py:22
20/12/10 15:38:01 INFO DAGScheduler: Registering RDD 13 (toPandas at /tmp/spark-6b081aa8-4a38-489f-9ffe-eed10e409391/userFiles-6604436f-6746-486a-b42f-87ca96b62dd2/darima.zip/darima/dlsa.py:22) as input to shuffle 1
20/12/10 15:38:01 INFO DAGScheduler: Got job 1 (toPandas at /tmp/spark-6b081aa8-4a38-489f-9ffe-eed10e409391/userFiles-6604436f-6746-486a-b42f-87ca96b62dd2/darima.zip/darima/dlsa.py:22) with 200 output partitions
20/12/10 15:38:01 INFO DAGScheduler: Final stage: ResultStage 3 (toPandas at /tmp/spark-6b081aa8-4a38-489f-9ffe-eed10e409391/userFiles-6604436f-6746-486a-b42f-87ca96b62dd2/darima.zip/darima/dlsa.py:22)
20/12/10 15:38:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
20/12/10 15:38:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
20/12/10 15:38:01 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[13] at toPandas at /tmp/spark-6b081aa8-4a38-489f-9ffe-eed10e409391/userFiles-6604436f-6746-486a-b42f-87ca96b62dd2/darima.zip/darima/dlsa.py:22), which has no missing parents
20/12/10 15:38:01 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 24.3 KiB, free 5.8 GiB)
20/12/10 15:38:01 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.6 KiB, free 5.8 GiB)
20/12/10 15:38:01 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.1.9:34905 (size: 11.6 KiB, free: 5.8 GiB)
20/12/10 15:38:01 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1223
20/12/10 15:38:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[13] at toPandas at /tmp/spark-6b081aa8-4a38-489f-9ffe-eed10e409391/userFiles-6604436f-6746-486a-b42f-87ca96b62dd2/darima.zip/darima/dlsa.py:22) (first 15 tasks are for partitions Vector(0))
20/12/10 15:38:01 INFO YarnScheduler: Adding task set 2.0 with 1 tasks
20/12/10 15:38:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, 192.168.1.9, executor 1, partition 0, NODE_LOCAL, 7779 bytes)
20/12/10 15:38:01 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.1.9:34817 (size: 11.6 KiB, free: 912.3 MiB)
20/12/10 15:38:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.1.9:34817 (size: 28.7 KiB, free: 912.3 MiB)
20/12/10 15:38:04 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 2793 ms on 192.168.1.9 (executor 1) (1/1)
20/12/10 15:38:04 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/12/10 15:38:04 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 37845
20/12/10 15:38:04 INFO DAGScheduler: ShuffleMapStage 2 (toPandas at /tmp/spark-6b081aa8-4a38-489f-9ffe-eed10e409391/userFiles-6604436f-6746-486a-b42f-87ca96b62dd2/darima.zip/darima/dlsa.py:22) finished in 2.823 s
20/12/10 15:38:04 INFO DAGScheduler: looking for newly runnable stages
20/12/10 15:38:04 INFO DAGScheduler: running: Set()
20/12/10 15:38:04 INFO DAGScheduler: waiting: Set(ResultStage 3)
20/12/10 15:38:04 INFO DAGScheduler: failed: Set()
20/12/10 15:38:04 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[18] at toPandas at /tmp/spark-6b081aa8-4a38-489f-9ffe-eed10e409391/userFiles-6604436f-6746-486a-b42f-87ca96b62dd2/darima.zip/darima/dlsa.py:22), which has no missing parents
20/12/10 15:38:04 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 428.1 KiB, free 5.8 GiB)
20/12/10 15:38:04 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 131.5 KiB, free 5.8 GiB)
20/12/10 15:38:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.1.9:34905 (size: 131.5 KiB, free: 5.8 GiB)
20/12/10 15:38:04 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1223
20/12/10 15:38:04 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 3 (MapPartitionsRDD[18] at toPandas at /tmp/spark-6b081aa8-4a38-489f-9ffe-eed10e409391/userFiles-6604436f-6746-486a-b42f-87ca96b62dd2/darima.zip/darima/dlsa.py:22) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
20/12/10 15:38:04 INFO YarnScheduler: Adding task set 3.0 with 200 tasks
20/12/10 15:38:04 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, 192.168.1.9, executor 1, partition 0, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:04 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 4, 192.168.1.9, executor 2, partition 1, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.1.9:34817 (size: 131.5 KiB, free: 912.1 MiB)
20/12/10 15:38:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.1.9:43683 (size: 131.5 KiB, free: 912.2 MiB)
20/12/10 15:38:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 192.168.1.9:39108
20/12/10 15:38:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 192.168.1.9:39114
20/12/10 15:38:15 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 5, 192.168.1.9, executor 2, partition 2, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:15 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 4) in 11159 ms on 192.168.1.9 (executor 2) (1/200)
20/12/10 15:38:16 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 6, 192.168.1.9, executor 1, partition 3, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:16 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 11568 ms on 192.168.1.9 (executor 1) (2/200)
20/12/10 15:38:18 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 7, 192.168.1.9, executor 2, partition 4, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:18 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 5) in 2381 ms on 192.168.1.9 (executor 2) (3/200)
20/12/10 15:38:20 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 8, 192.168.1.9, executor 2, partition 5, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:20 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 7) in 2032 ms on 192.168.1.9 (executor 2) (4/200)
20/12/10 15:38:21 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 9, 192.168.1.9, executor 1, partition 6, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:21 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 6) in 5180 ms on 192.168.1.9 (executor 1) (5/200)
20/12/10 15:38:23 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 10, 192.168.1.9, executor 2, partition 7, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:23 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 8) in 3097 ms on 192.168.1.9 (executor 2) (6/200)
20/12/10 15:38:23 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 11, 192.168.1.9, executor 1, partition 8, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:23 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 9) in 2509 ms on 192.168.1.9 (executor 1) (7/200)
20/12/10 15:38:25 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 12, 192.168.1.9, executor 2, partition 9, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:25 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 10) in 2770 ms on 192.168.1.9 (executor 2) (8/200)
20/12/10 15:38:26 INFO TaskSetManager: Starting task 10.0 in stage 3.0 (TID 13, 192.168.1.9, executor 1, partition 10, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:26 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 11) in 2775 ms on 192.168.1.9 (executor 1) (9/200)
20/12/10 15:38:28 INFO TaskSetManager: Starting task 11.0 in stage 3.0 (TID 14, 192.168.1.9, executor 1, partition 11, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:28 INFO TaskSetManager: Finished task 10.0 in stage 3.0 (TID 13) in 2066 ms on 192.168.1.9 (executor 1) (10/200)
20/12/10 15:38:29 INFO TaskSetManager: Starting task 12.0 in stage 3.0 (TID 15, 192.168.1.9, executor 2, partition 12, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:29 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 12) in 3125 ms on 192.168.1.9 (executor 2) (11/200)
20/12/10 15:38:32 INFO TaskSetManager: Starting task 13.0 in stage 3.0 (TID 16, 192.168.1.9, executor 2, partition 13, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:32 INFO TaskSetManager: Finished task 12.0 in stage 3.0 (TID 15) in 3898 ms on 192.168.1.9 (executor 2) (12/200)
20/12/10 15:38:34 INFO TaskSetManager: Starting task 14.0 in stage 3.0 (TID 17, 192.168.1.9, executor 1, partition 14, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:34 INFO TaskSetManager: Finished task 11.0 in stage 3.0 (TID 14) in 5649 ms on 192.168.1.9 (executor 1) (13/200)
20/12/10 15:38:35 INFO TaskSetManager: Starting task 15.0 in stage 3.0 (TID 18, 192.168.1.9, executor 2, partition 15, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:35 INFO TaskSetManager: Finished task 13.0 in stage 3.0 (TID 16) in 2119 ms on 192.168.1.9 (executor 2) (14/200)
20/12/10 15:38:36 INFO TaskSetManager: Starting task 16.0 in stage 3.0 (TID 19, 192.168.1.9, executor 2, partition 16, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:36 INFO TaskSetManager: Finished task 15.0 in stage 3.0 (TID 18) in 1857 ms on 192.168.1.9 (executor 2) (15/200)
20/12/10 15:38:38 INFO TaskSetManager: Starting task 17.0 in stage 3.0 (TID 20, 192.168.1.9, executor 1, partition 17, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:38 INFO TaskSetManager: Finished task 14.0 in stage 3.0 (TID 17) in 3779 ms on 192.168.1.9 (executor 1) (16/200)
20/12/10 15:38:39 INFO TaskSetManager: Starting task 18.0 in stage 3.0 (TID 21, 192.168.1.9, executor 2, partition 18, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:39 INFO TaskSetManager: Finished task 16.0 in stage 3.0 (TID 19) in 2084 ms on 192.168.1.9 (executor 2) (17/200)
20/12/10 15:38:39 INFO TaskSetManager: Starting task 19.0 in stage 3.0 (TID 22, 192.168.1.9, executor 1, partition 19, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:39 INFO TaskSetManager: Finished task 17.0 in stage 3.0 (TID 20) in 1117 ms on 192.168.1.9 (executor 1) (18/200)
20/12/10 15:38:39 INFO TaskSetManager: Starting task 20.0 in stage 3.0 (TID 23, 192.168.1.9, executor 2, partition 20, NODE_LOCAL, 7336 bytes)
20/12/10 15:38:39 INFO TaskSetManager: Finished task 18.0 in stage 3.0 (TID 21) in 873 ms on 192.168.1.9 (executor 2) (19/200)
20/12/10 15:38:39 INFO SparkContext: Invoking stop() from shutdown hook
20/12/10 15:38:39 INFO SparkUI: Stopped Spark web UI at http://192.168.1.9:4040
20/12/10 15:38:39 INFO DAGScheduler: Job 1 failed: toPandas at /tmp/spark-6b081aa8-4a38-489f-9ffe-eed10e409391/userFiles-6604436f-6746-486a-b42f-87ca96b62dd2/darima.zip/darima/dlsa.py:22, took 38.366713 s
20/12/10 15:38:39 INFO DAGScheduler: ResultStage 3 (toPandas at /tmp/spark-6b081aa8-4a38-489f-9ffe-eed10e409391/userFiles-6604436f-6746-486a-b42f-87ca96b62dd2/darima.zip/darima/dlsa.py:22) failed in 35.491 s due to Stage cancelled because SparkContext was shut down
20/12/10 15:38:39 INFO YarnClientSchedulerBackend: Interrupting monitor thread
20/12/10 15:38:40 INFO YarnClientSchedulerBackend: Shutting down all executors
20/12/10 15:38:40 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
20/12/10 15:38:40 INFO YarnClientSchedulerBackend: YARN client scheduler backend Stopped
20/12/10 15:38:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/12/10 15:38:40 INFO MemoryStore: MemoryStore cleared
20/12/10 15:38:40 INFO BlockManager: BlockManager stopped
20/12/10 15:38:40 INFO BlockManagerMaster: BlockManagerMaster stopped
20/12/10 15:38:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/12/10 15:38:40 INFO SparkContext: Successfully stopped SparkContext
20/12/10 15:38:40 INFO ShutdownHookManager: Shutdown hook called
20/12/10 15:38:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-b9829692-2458-4b4a-938e-8a5bf17e4faa
20/12/10 15:38:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b081aa8-4a38-489f-9ffe-eed10e409391/pyspark-df5b4e56-632d-459a-aa0a-9927bdc58f8e
20/12/10 15:38:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b081aa8-4a38-489f-9ffe-eed10e409391
20/12/10 15:39:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/12/10 15:39:38 INFO SecurityManager: Changing view acls to: bsuconn
20/12/10 15:39:38 INFO SecurityManager: Changing modify acls to: bsuconn
20/12/10 15:39:38 INFO SecurityManager: Changing view acls groups to: 
20/12/10 15:39:38 INFO SecurityManager: Changing modify acls groups to: 
20/12/10 15:39:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(bsuconn); groups with view permissions: Set(); users  with modify permissions: Set(bsuconn); groups with modify permissions: Set()
20/12/10 15:39:38 INFO SparkContext: Running Spark version 3.0.1
20/12/10 15:39:38 INFO ResourceUtils: ==============================================================
20/12/10 15:39:38 INFO ResourceUtils: Resources for spark.driver:

20/12/10 15:39:38 INFO ResourceUtils: ==============================================================
20/12/10 15:39:38 INFO SparkContext: Submitted application: Spark DARIMA App
20/12/10 15:39:38 INFO SecurityManager: Changing view acls to: bsuconn
20/12/10 15:39:38 INFO SecurityManager: Changing modify acls to: bsuconn
20/12/10 15:39:38 INFO SecurityManager: Changing view acls groups to: 
20/12/10 15:39:38 INFO SecurityManager: Changing modify acls groups to: 
20/12/10 15:39:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(bsuconn); groups with view permissions: Set(); users  with modify permissions: Set(bsuconn); groups with modify permissions: Set()
20/12/10 15:39:39 INFO Utils: Successfully started service 'sparkDriver' on port 41175.
20/12/10 15:39:39 INFO SparkEnv: Registering MapOutputTracker
20/12/10 15:39:39 INFO SparkEnv: Registering BlockManagerMaster
20/12/10 15:39:39 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/12/10 15:39:39 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/12/10 15:39:39 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
20/12/10 15:39:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-41c8215f-0ab9-4b4f-9831-c39f80a491f1
20/12/10 15:39:39 INFO MemoryStore: MemoryStore started with capacity 5.8 GiB
20/12/10 15:39:39 INFO SparkEnv: Registering OutputCommitCoordinator
20/12/10 15:39:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/12/10 15:39:39 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.9:4040
20/12/10 15:39:40 INFO RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
20/12/10 15:39:40 INFO Client: Requesting a new application from cluster with 1 NodeManagers
20/12/10 15:39:41 INFO Configuration: resource-types.xml not found
20/12/10 15:39:41 INFO ResourceUtils: Unable to find 'resource-types.xml'.
20/12/10 15:39:41 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
20/12/10 15:39:41 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/12/10 15:39:41 INFO Client: Setting up container launch context for our AM
20/12/10 15:39:41 INFO Client: Setting up the launch environment for our AM container
20/12/10 15:39:41 INFO Client: Preparing resources for our AM container
20/12/10 15:39:41 WARN Client: Failed to cleanup staging dir hdfs://localhost:9000/user/bsuconn/.sparkStaging/application_1607632772089_0001
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/bsuconn/.sparkStaging/application_1607632772089_0001. Name node is in safe mode.
The reported blocks 37 has reached the threshold 0.9990 of total blocks 37. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 11 seconds. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1463)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3084)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1114)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:705)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1608)
	at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:952)
	at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:949)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:959)
	at org.apache.spark.deploy.yarn.Client.cleanupStagingDirInternal$1(Client.scala:226)
	at org.apache.spark.deploy.yarn.Client.cleanupStagingDir(Client.scala:235)
	at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:209)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:60)
	at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:201)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:555)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:238)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot delete /user/bsuconn/.sparkStaging/application_1607632772089_0001. Name node is in safe mode.
The reported blocks 37 has reached the threshold 0.9990 of total blocks 37. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 11 seconds. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1463)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3084)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1114)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:705)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.delete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.delete(ClientNamenodeProtocolTranslatorPB.java:637)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy20.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1606)
	... 22 more
20/12/10 15:39:41 ERROR SparkContext: Error initializing SparkContext.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /user/bsuconn/.sparkStaging/application_1607632772089_0001. Name node is in safe mode.
The reported blocks 37 has reached the threshold 0.9990 of total blocks 37. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 11 seconds. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1463)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3232)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1145)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:720)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2426)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2400)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1324)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1321)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1338)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1313)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2275)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:674)
	at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:441)
	at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:876)
	at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:196)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:60)
	at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:201)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:555)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:238)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create directory /user/bsuconn/.sparkStaging/application_1607632772089_0001. Name node is in safe mode.
The reported blocks 37 has reached the threshold 0.9990 of total blocks 37. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 11 seconds. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1463)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3232)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1145)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:720)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:656)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy20.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2424)
	... 26 more
20/12/10 15:39:41 INFO SparkUI: Stopped Spark web UI at http://192.168.1.9:4040
20/12/10 15:39:41 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!
20/12/10 15:39:41 INFO YarnClientSchedulerBackend: Shutting down all executors
20/12/10 15:39:41 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
20/12/10 15:39:41 INFO YarnClientSchedulerBackend: YARN client scheduler backend Stopped
20/12/10 15:39:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/12/10 15:39:41 INFO MemoryStore: MemoryStore cleared
20/12/10 15:39:41 INFO BlockManager: BlockManager stopped
20/12/10 15:39:41 INFO BlockManagerMaster: BlockManagerMaster stopped
20/12/10 15:39:41 WARN MetricsSystem: Stopping a MetricsSystem that is not running
20/12/10 15:39:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/12/10 15:39:41 INFO SparkContext: Successfully stopped SparkContext
20/12/10 15:39:41 INFO ShutdownHookManager: Shutdown hook called
20/12/10 15:39:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-e0581186-cd62-4c8b-a977-84d193bda858
20/12/10 15:39:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-30cc7211-2c7b-457d-a118-f4d7a711c9df
20/12/10 15:39:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/12/10 15:39:44 INFO SecurityManager: Changing view acls to: bsuconn
20/12/10 15:39:44 INFO SecurityManager: Changing modify acls to: bsuconn
20/12/10 15:39:44 INFO SecurityManager: Changing view acls groups to: 
20/12/10 15:39:44 INFO SecurityManager: Changing modify acls groups to: 
20/12/10 15:39:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(bsuconn); groups with view permissions: Set(); users  with modify permissions: Set(bsuconn); groups with modify permissions: Set()
20/12/10 15:39:44 INFO SparkContext: Running Spark version 3.0.1
20/12/10 15:39:44 INFO ResourceUtils: ==============================================================
20/12/10 15:39:44 INFO ResourceUtils: Resources for spark.driver:

20/12/10 15:39:44 INFO ResourceUtils: ==============================================================
20/12/10 15:39:44 INFO SparkContext: Submitted application: Spark DARIMA App
20/12/10 15:39:45 INFO SecurityManager: Changing view acls to: bsuconn
20/12/10 15:39:45 INFO SecurityManager: Changing modify acls to: bsuconn
20/12/10 15:39:45 INFO SecurityManager: Changing view acls groups to: 
20/12/10 15:39:45 INFO SecurityManager: Changing modify acls groups to: 
20/12/10 15:39:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(bsuconn); groups with view permissions: Set(); users  with modify permissions: Set(bsuconn); groups with modify permissions: Set()
20/12/10 15:39:45 INFO Utils: Successfully started service 'sparkDriver' on port 34745.
20/12/10 15:39:45 INFO SparkEnv: Registering MapOutputTracker
20/12/10 15:39:45 INFO SparkEnv: Registering BlockManagerMaster
20/12/10 15:39:45 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/12/10 15:39:45 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/12/10 15:39:45 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
20/12/10 15:39:45 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cafc0910-14b4-456a-b270-69e591f49eef
20/12/10 15:39:45 INFO MemoryStore: MemoryStore started with capacity 5.8 GiB
20/12/10 15:39:45 INFO SparkEnv: Registering OutputCommitCoordinator
20/12/10 15:39:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/12/10 15:39:46 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.9:4040
20/12/10 15:39:46 INFO RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
20/12/10 15:39:47 INFO Client: Requesting a new application from cluster with 1 NodeManagers
20/12/10 15:39:47 INFO Configuration: resource-types.xml not found
20/12/10 15:39:47 INFO ResourceUtils: Unable to find 'resource-types.xml'.
20/12/10 15:39:47 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
20/12/10 15:39:47 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/12/10 15:39:47 INFO Client: Setting up container launch context for our AM
20/12/10 15:39:47 INFO Client: Setting up the launch environment for our AM container
20/12/10 15:39:47 INFO Client: Preparing resources for our AM container
20/12/10 15:39:47 WARN Client: Failed to cleanup staging dir hdfs://localhost:9000/user/bsuconn/.sparkStaging/application_1607632772089_0002
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/bsuconn/.sparkStaging/application_1607632772089_0002. Name node is in safe mode.
The reported blocks 37 has reached the threshold 0.9990 of total blocks 37. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 5 seconds. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1463)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3084)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1114)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:705)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1608)
	at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:952)
	at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:949)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:959)
	at org.apache.spark.deploy.yarn.Client.cleanupStagingDirInternal$1(Client.scala:226)
	at org.apache.spark.deploy.yarn.Client.cleanupStagingDir(Client.scala:235)
	at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:209)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:60)
	at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:201)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:555)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:238)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot delete /user/bsuconn/.sparkStaging/application_1607632772089_0002. Name node is in safe mode.
The reported blocks 37 has reached the threshold 0.9990 of total blocks 37. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 5 seconds. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1463)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3084)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1114)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:705)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.delete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.delete(ClientNamenodeProtocolTranslatorPB.java:637)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy20.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1606)
	... 22 more
20/12/10 15:39:47 ERROR SparkContext: Error initializing SparkContext.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /user/bsuconn/.sparkStaging/application_1607632772089_0002. Name node is in safe mode.
The reported blocks 37 has reached the threshold 0.9990 of total blocks 37. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 5 seconds. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1463)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3232)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1145)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:720)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2426)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2400)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1324)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1321)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1338)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1313)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2275)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:674)
	at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:441)
	at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:876)
	at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:196)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:60)
	at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:201)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:555)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:238)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create directory /user/bsuconn/.sparkStaging/application_1607632772089_0002. Name node is in safe mode.
The reported blocks 37 has reached the threshold 0.9990 of total blocks 37. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 5 seconds. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1463)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3232)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1145)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:720)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:656)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy20.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2424)
	... 26 more
20/12/10 15:39:47 INFO SparkUI: Stopped Spark web UI at http://192.168.1.9:4040
20/12/10 15:39:47 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!
20/12/10 15:39:47 INFO YarnClientSchedulerBackend: Shutting down all executors
20/12/10 15:39:47 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
20/12/10 15:39:47 INFO YarnClientSchedulerBackend: YARN client scheduler backend Stopped
20/12/10 15:39:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/12/10 15:39:47 INFO MemoryStore: MemoryStore cleared
20/12/10 15:39:47 INFO BlockManager: BlockManager stopped
20/12/10 15:39:47 INFO BlockManagerMaster: BlockManagerMaster stopped
20/12/10 15:39:47 WARN MetricsSystem: Stopping a MetricsSystem that is not running
20/12/10 15:39:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/12/10 15:39:47 INFO SparkContext: Successfully stopped SparkContext
20/12/10 15:39:48 INFO ShutdownHookManager: Shutdown hook called
20/12/10 15:39:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-04e13af3-23e1-41ec-a0fb-73d465b9a267
20/12/10 15:39:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-30808c1f-6e95-4e08-8c3f-66815da09bf2
20/12/10 15:39:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/12/10 15:39:50 INFO SecurityManager: Changing view acls to: bsuconn
20/12/10 15:39:50 INFO SecurityManager: Changing modify acls to: bsuconn
20/12/10 15:39:50 INFO SecurityManager: Changing view acls groups to: 
20/12/10 15:39:50 INFO SecurityManager: Changing modify acls groups to: 
20/12/10 15:39:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(bsuconn); groups with view permissions: Set(); users  with modify permissions: Set(bsuconn); groups with modify permissions: Set()
20/12/10 15:39:51 INFO SparkContext: Running Spark version 3.0.1
20/12/10 15:39:51 INFO ResourceUtils: ==============================================================
20/12/10 15:39:51 INFO ResourceUtils: Resources for spark.driver:

20/12/10 15:39:51 INFO ResourceUtils: ==============================================================
20/12/10 15:39:51 INFO SparkContext: Submitted application: Spark DARIMA App
20/12/10 15:39:51 INFO SecurityManager: Changing view acls to: bsuconn
20/12/10 15:39:51 INFO SecurityManager: Changing modify acls to: bsuconn
20/12/10 15:39:51 INFO SecurityManager: Changing view acls groups to: 
20/12/10 15:39:51 INFO SecurityManager: Changing modify acls groups to: 
20/12/10 15:39:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(bsuconn); groups with view permissions: Set(); users  with modify permissions: Set(bsuconn); groups with modify permissions: Set()
20/12/10 15:39:51 INFO Utils: Successfully started service 'sparkDriver' on port 38357.
20/12/10 15:39:52 INFO SparkEnv: Registering MapOutputTracker
20/12/10 15:39:52 INFO SparkEnv: Registering BlockManagerMaster
20/12/10 15:39:52 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/12/10 15:39:52 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/12/10 15:39:52 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
20/12/10 15:39:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3e25315c-bdc8-4058-8af6-e6353726fc80
20/12/10 15:39:52 INFO MemoryStore: MemoryStore started with capacity 5.8 GiB
20/12/10 15:39:52 INFO SparkEnv: Registering OutputCommitCoordinator
20/12/10 15:39:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/12/10 15:39:52 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.9:4040
20/12/10 15:39:53 INFO RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
20/12/10 15:39:53 INFO Client: Requesting a new application from cluster with 1 NodeManagers
20/12/10 15:39:53 INFO Configuration: resource-types.xml not found
20/12/10 15:39:53 INFO ResourceUtils: Unable to find 'resource-types.xml'.
20/12/10 15:39:53 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
20/12/10 15:39:53 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/12/10 15:39:53 INFO Client: Setting up container launch context for our AM
20/12/10 15:39:53 INFO Client: Setting up the launch environment for our AM container
20/12/10 15:39:53 INFO Client: Preparing resources for our AM container
20/12/10 15:39:53 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
20/12/10 15:39:55 INFO Client: Uploading resource file:/tmp/spark-8bc0eb3c-92a7-4e21-8a4f-4415f689a7de/__spark_libs__11020369082584949512.zip -> hdfs://localhost:9000/user/bsuconn/.sparkStaging/application_1607632772089_0003/__spark_libs__11020369082584949512.zip
20/12/10 15:39:57 INFO Client: Uploading resource file:/home/bsuconn/spark/spark-3.0.1-bin-hadoop3.2/python/lib/pyspark.zip -> hdfs://localhost:9000/user/bsuconn/.sparkStaging/application_1607632772089_0003/pyspark.zip
20/12/10 15:39:57 INFO Client: Uploading resource file:/home/bsuconn/spark/spark-3.0.1-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip -> hdfs://localhost:9000/user/bsuconn/.sparkStaging/application_1607632772089_0003/py4j-0.10.9-src.zip
20/12/10 15:39:57 INFO Client: Uploading resource file:/tmp/spark-8bc0eb3c-92a7-4e21-8a4f-4415f689a7de/__spark_conf__8084066241574672652.zip -> hdfs://localhost:9000/user/bsuconn/.sparkStaging/application_1607632772089_0003/__spark_conf__.zip
20/12/10 15:39:58 INFO SecurityManager: Changing view acls to: bsuconn
20/12/10 15:39:58 INFO SecurityManager: Changing modify acls to: bsuconn
20/12/10 15:39:58 INFO SecurityManager: Changing view acls groups to: 
20/12/10 15:39:58 INFO SecurityManager: Changing modify acls groups to: 
20/12/10 15:39:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(bsuconn); groups with view permissions: Set(); users  with modify permissions: Set(bsuconn); groups with modify permissions: Set()
20/12/10 15:39:58 INFO Client: Submitting application application_1607632772089_0003 to ResourceManager
20/12/10 15:39:58 INFO YarnClientImpl: Submitted application application_1607632772089_0003
20/12/10 15:39:59 INFO Client: Application report for application_1607632772089_0003 (state: ACCEPTED)
20/12/10 15:39:59 INFO Client: 
	 client token: N/A
	 diagnostics: [Thu Dec 10 15:39:59 -0500 2020] Scheduler has assigned a container for AM, waiting for AM container to be launched
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1607632798475
	 final status: UNDEFINED
	 tracking URL: http://pop-os:8088/proxy/application_1607632772089_0003/
	 user: bsuconn
20/12/10 15:40:00 INFO Client: Application report for application_1607632772089_0003 (state: ACCEPTED)
20/12/10 15:40:01 INFO Client: Application report for application_1607632772089_0003 (state: ACCEPTED)
20/12/10 15:40:02 INFO Client: Application report for application_1607632772089_0003 (state: ACCEPTED)
20/12/10 15:40:03 INFO Client: Application report for application_1607632772089_0003 (state: ACCEPTED)
20/12/10 15:40:04 INFO Client: Application report for application_1607632772089_0003 (state: ACCEPTED)
20/12/10 15:40:05 INFO Client: Application report for application_1607632772089_0003 (state: RUNNING)
20/12/10 15:40:05 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 192.168.1.9
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1607632798475
	 final status: UNDEFINED
	 tracking URL: http://pop-os:8088/proxy/application_1607632772089_0003/
	 user: bsuconn
20/12/10 15:40:05 INFO YarnClientSchedulerBackend: Application application_1607632772089_0003 has started running.
20/12/10 15:40:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34211.
20/12/10 15:40:05 INFO NettyBlockTransferService: Server created on 192.168.1.9:34211
20/12/10 15:40:05 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/12/10 15:40:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.9, 34211, None)
20/12/10 15:40:05 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.9:34211 with 5.8 GiB RAM, BlockManagerId(driver, 192.168.1.9, 34211, None)
20/12/10 15:40:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.9, 34211, None)
20/12/10 15:40:05 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.1.9, 34211, None)
20/12/10 15:40:05 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> pop-os, PROXY_URI_BASES -> http://pop-os:8088/proxy/application_1607632772089_0003), /proxy/application_1607632772089_0003
20/12/10 15:40:05 INFO ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
20/12/10 15:40:06 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
20/12/10 15:40:10 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
20/12/10 15:40:11 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.9:59650) with ID 1
20/12/10 15:40:12 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.9:44815 with 912.3 MiB RAM, BlockManagerId(1, 192.168.1.9, 44815, None)
20/12/10 15:40:13 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.9:59654) with ID 2
20/12/10 15:40:13 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.9:36951 with 912.3 MiB RAM, BlockManagerId(2, 192.168.1.9, 36951, None)
20/12/10 15:40:22 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)
20/12/10 15:40:23 INFO SharedState: loading hive config file: file:/home/bsuconn/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
20/12/10 15:40:23 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/bsuconn/Documents/Fall_2020/STAT_5825/Project/spark-warehouse').
20/12/10 15:40:23 INFO SharedState: Warehouse path is 'file:/home/bsuconn/Documents/Fall_2020/STAT_5825/Project/spark-warehouse'.
20/12/10 15:40:23 INFO ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
20/12/10 15:40:23 INFO ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
20/12/10 15:40:23 INFO ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
20/12/10 15:40:23 INFO ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
20/12/10 15:40:23 INFO ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
20/12/10 15:40:23 INFO SparkContext: Added file darima-master/bash/darima.zip at spark://192.168.1.9:38357/files/darima.zip with timestamp 1607632823927
20/12/10 15:40:23 INFO Utils: Copying /home/bsuconn/Documents/Fall_2020/STAT_5825/Project/darima-master/bash/darima.zip to /tmp/spark-8bc0eb3c-92a7-4e21-8a4f-4415f689a7de/userFiles-5aa891bb-63e0-48b5-bc49-60ffed296deb/darima.zip
20/12/10 15:40:26 INFO InMemoryFileIndex: It took 137 ms to list leaf files for 1 paths.
20/12/10 15:40:28 INFO InMemoryFileIndex: It took 12 ms to list leaf files for 1 paths.
20/12/10 15:40:28 INFO FileSourceStrategy: Pruning directories with: 
20/12/10 15:40:28 INFO FileSourceStrategy: Pushed Filters: 
20/12/10 15:40:28 INFO FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, t#1,traffic_volume#0)
20/12/10 15:40:28 INFO FileSourceStrategy: Output Data Schema: struct<traffic_volume: double, t: string>
20/12/10 15:40:29 INFO CodeGenerator: Code generated in 289.303729 ms
20/12/10 15:40:29 INFO CodeGenerator: Code generated in 32.983871 ms
20/12/10 15:40:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 177.4 KiB, free 5.8 GiB)
20/12/10 15:40:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 28.7 KiB, free 5.8 GiB)
20/12/10 15:40:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.1.9:34211 (size: 28.7 KiB, free: 5.8 GiB)
20/12/10 15:40:29 INFO SparkContext: Created broadcast 0 from count at NativeMethodAccessorImpl.java:0
20/12/10 15:40:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 15:40:30 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
20/12/10 15:40:30 INFO DAGScheduler: Registering RDD 3 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
20/12/10 15:40:30 INFO DAGScheduler: Got job 0 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 15:40:30 INFO DAGScheduler: Final stage: ResultStage 1 (count at NativeMethodAccessorImpl.java:0)
20/12/10 15:40:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
20/12/10 15:40:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
20/12/10 15:40:30 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 15:40:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 16.0 KiB, free 5.8 GiB)
20/12/10 15:40:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 5.8 GiB)
20/12/10 15:40:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.1.9:34211 (size: 8.0 KiB, free: 5.8 GiB)
20/12/10 15:40:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
20/12/10 15:40:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 15:40:30 INFO YarnScheduler: Adding task set 0.0 with 1 tasks
20/12/10 15:40:30 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.1.9, executor 1, partition 0, NODE_LOCAL, 7779 bytes)
20/12/10 15:40:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.1.9:44815 (size: 8.0 KiB, free: 912.3 MiB)
20/12/10 15:40:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.1.9:44815 (size: 28.7 KiB, free: 912.3 MiB)
20/12/10 15:40:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3332 ms on 192.168.1.9 (executor 1) (1/1)
20/12/10 15:40:33 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/12/10 15:40:33 INFO DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 3.514 s
20/12/10 15:40:33 INFO DAGScheduler: looking for newly runnable stages
20/12/10 15:40:33 INFO DAGScheduler: running: Set()
20/12/10 15:40:33 INFO DAGScheduler: waiting: Set(ResultStage 1)
20/12/10 15:40:33 INFO DAGScheduler: failed: Set()
20/12/10 15:40:33 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 15:40:33 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.1 KiB, free 5.8 GiB)
20/12/10 15:40:33 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 5.8 GiB)
20/12/10 15:40:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.1.9:34211 (size: 5.0 KiB, free: 5.8 GiB)
20/12/10 15:40:33 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1223
20/12/10 15:40:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 15:40:33 INFO YarnScheduler: Adding task set 1.0 with 1 tasks
20/12/10 15:40:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 192.168.1.9, executor 2, partition 0, NODE_LOCAL, 7336 bytes)
20/12/10 15:40:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.1.9:36951 (size: 5.0 KiB, free: 912.3 MiB)
20/12/10 15:40:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 192.168.1.9:59654
20/12/10 15:40:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1849 ms on 192.168.1.9 (executor 2) (1/1)
20/12/10 15:40:35 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/12/10 15:40:35 INFO DAGScheduler: ResultStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.868 s
20/12/10 15:40:35 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
20/12/10 15:40:35 INFO YarnScheduler: Killing all running tasks in stage 1: Stage finished
20/12/10 15:40:35 INFO DAGScheduler: Job 0 finished: count at NativeMethodAccessorImpl.java:0, took 5.506810 s
20/12/10 15:40:37 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.1.9:34211 in memory (size: 5.0 KiB, free: 5.8 GiB)
20/12/10 15:40:37 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.1.9:36951 in memory (size: 5.0 KiB, free: 912.3 MiB)
20/12/10 15:40:37 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.1.9:34211 in memory (size: 8.0 KiB, free: 5.8 GiB)
20/12/10 15:40:37 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.1.9:44815 in memory (size: 8.0 KiB, free: 912.3 MiB)
20/12/10 15:40:38 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
20/12/10 15:40:39 INFO FileSourceStrategy: Pruning directories with: 
20/12/10 15:40:39 INFO FileSourceStrategy: Pushed Filters: 
20/12/10 15:40:39 INFO FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, t#1,traffic_volume#0)
20/12/10 15:40:39 INFO FileSourceStrategy: Output Data Schema: struct<traffic_volume: double, t: string>
20/12/10 15:40:39 INFO CodeGenerator: Code generated in 29.15708 ms
20/12/10 15:40:39 INFO CodeGenerator: Code generated in 19.382625 ms
20/12/10 15:40:39 INFO CodeGenerator: Code generated in 37.004763 ms
20/12/10 15:40:39 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 177.4 KiB, free 5.8 GiB)
20/12/10 15:40:39 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 28.7 KiB, free 5.8 GiB)
20/12/10 15:40:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.1.9:34211 (size: 28.7 KiB, free: 5.8 GiB)
20/12/10 15:40:39 INFO SparkContext: Created broadcast 3 from toPandas at /tmp/spark-8bc0eb3c-92a7-4e21-8a4f-4415f689a7de/userFiles-5aa891bb-63e0-48b5-bc49-60ffed296deb/darima.zip/darima/dlsa.py:22
20/12/10 15:40:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 15:40:39 INFO SparkContext: Starting job: toPandas at /tmp/spark-8bc0eb3c-92a7-4e21-8a4f-4415f689a7de/userFiles-5aa891bb-63e0-48b5-bc49-60ffed296deb/darima.zip/darima/dlsa.py:22
20/12/10 15:40:39 INFO DAGScheduler: Registering RDD 13 (toPandas at /tmp/spark-8bc0eb3c-92a7-4e21-8a4f-4415f689a7de/userFiles-5aa891bb-63e0-48b5-bc49-60ffed296deb/darima.zip/darima/dlsa.py:22) as input to shuffle 1
20/12/10 15:40:39 INFO DAGScheduler: Got job 1 (toPandas at /tmp/spark-8bc0eb3c-92a7-4e21-8a4f-4415f689a7de/userFiles-5aa891bb-63e0-48b5-bc49-60ffed296deb/darima.zip/darima/dlsa.py:22) with 200 output partitions
20/12/10 15:40:39 INFO DAGScheduler: Final stage: ResultStage 3 (toPandas at /tmp/spark-8bc0eb3c-92a7-4e21-8a4f-4415f689a7de/userFiles-5aa891bb-63e0-48b5-bc49-60ffed296deb/darima.zip/darima/dlsa.py:22)
20/12/10 15:40:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
20/12/10 15:40:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
20/12/10 15:40:39 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[13] at toPandas at /tmp/spark-8bc0eb3c-92a7-4e21-8a4f-4415f689a7de/userFiles-5aa891bb-63e0-48b5-bc49-60ffed296deb/darima.zip/darima/dlsa.py:22), which has no missing parents
20/12/10 15:40:39 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 24.3 KiB, free 5.8 GiB)
20/12/10 15:40:39 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.6 KiB, free 5.8 GiB)
20/12/10 15:40:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.1.9:34211 (size: 11.6 KiB, free: 5.8 GiB)
20/12/10 15:40:39 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1223
20/12/10 15:40:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[13] at toPandas at /tmp/spark-8bc0eb3c-92a7-4e21-8a4f-4415f689a7de/userFiles-5aa891bb-63e0-48b5-bc49-60ffed296deb/darima.zip/darima/dlsa.py:22) (first 15 tasks are for partitions Vector(0))
20/12/10 15:40:39 INFO YarnScheduler: Adding task set 2.0 with 1 tasks
20/12/10 15:40:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, 192.168.1.9, executor 2, partition 0, NODE_LOCAL, 7779 bytes)
20/12/10 15:40:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.1.9:36951 (size: 11.6 KiB, free: 912.3 MiB)
20/12/10 15:40:40 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.1.9:36951 (size: 28.7 KiB, free: 912.3 MiB)
20/12/10 15:40:43 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 3656 ms on 192.168.1.9 (executor 2) (1/1)
20/12/10 15:40:43 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/12/10 15:40:43 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 39229
20/12/10 15:40:43 INFO DAGScheduler: ShuffleMapStage 2 (toPandas at /tmp/spark-8bc0eb3c-92a7-4e21-8a4f-4415f689a7de/userFiles-5aa891bb-63e0-48b5-bc49-60ffed296deb/darima.zip/darima/dlsa.py:22) finished in 3.693 s
20/12/10 15:40:43 INFO DAGScheduler: looking for newly runnable stages
20/12/10 15:40:43 INFO DAGScheduler: running: Set()
20/12/10 15:40:43 INFO DAGScheduler: waiting: Set(ResultStage 3)
20/12/10 15:40:43 INFO DAGScheduler: failed: Set()
20/12/10 15:40:43 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[18] at toPandas at /tmp/spark-8bc0eb3c-92a7-4e21-8a4f-4415f689a7de/userFiles-5aa891bb-63e0-48b5-bc49-60ffed296deb/darima.zip/darima/dlsa.py:22), which has no missing parents
20/12/10 15:40:43 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 428.1 KiB, free 5.8 GiB)
20/12/10 15:40:43 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 131.5 KiB, free 5.8 GiB)
20/12/10 15:40:43 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.1.9:34211 (size: 131.5 KiB, free: 5.8 GiB)
20/12/10 15:40:43 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1223
20/12/10 15:40:43 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 3 (MapPartitionsRDD[18] at toPandas at /tmp/spark-8bc0eb3c-92a7-4e21-8a4f-4415f689a7de/userFiles-5aa891bb-63e0-48b5-bc49-60ffed296deb/darima.zip/darima/dlsa.py:22) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
20/12/10 15:40:43 INFO YarnScheduler: Adding task set 3.0 with 200 tasks
20/12/10 15:40:43 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, 192.168.1.9, executor 1, partition 0, NODE_LOCAL, 7336 bytes)
20/12/10 15:40:43 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 4, 192.168.1.9, executor 2, partition 1, NODE_LOCAL, 7336 bytes)
20/12/10 15:40:43 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.1.9:36951 (size: 131.5 KiB, free: 912.1 MiB)
20/12/10 15:40:43 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.1.9:44815 (size: 131.5 KiB, free: 912.1 MiB)
20/12/10 15:40:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 192.168.1.9:59654
20/12/10 15:40:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 192.168.1.9:59650
20/12/10 15:40:53 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 5, 192.168.1.9, executor 2, partition 2, NODE_LOCAL, 7336 bytes)
20/12/10 15:40:53 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 4) in 10059 ms on 192.168.1.9 (executor 2) (1/200)
20/12/10 15:40:55 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 6, 192.168.1.9, executor 1, partition 3, NODE_LOCAL, 7336 bytes)
20/12/10 15:40:55 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 11716 ms on 192.168.1.9 (executor 1) (2/200)
20/12/10 15:40:55 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 7, 192.168.1.9, executor 2, partition 4, NODE_LOCAL, 7336 bytes)
20/12/10 15:40:55 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 5) in 2044 ms on 192.168.1.9 (executor 2) (3/200)
20/12/10 15:40:57 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 8, 192.168.1.9, executor 2, partition 5, NODE_LOCAL, 7336 bytes)
20/12/10 15:40:57 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 7) in 2103 ms on 192.168.1.9 (executor 2) (4/200)
20/12/10 15:40:59 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 9, 192.168.1.9, executor 1, partition 6, NODE_LOCAL, 7336 bytes)
20/12/10 15:40:59 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 6) in 4520 ms on 192.168.1.9 (executor 1) (5/200)
20/12/10 15:41:00 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 10, 192.168.1.9, executor 2, partition 7, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:00 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 8) in 3079 ms on 192.168.1.9 (executor 2) (6/200)
20/12/10 15:41:02 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 11, 192.168.1.9, executor 1, partition 8, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:02 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 9) in 2443 ms on 192.168.1.9 (executor 1) (7/200)
20/12/10 15:41:02 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 12, 192.168.1.9, executor 2, partition 9, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:02 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 10) in 2141 ms on 192.168.1.9 (executor 2) (8/200)
20/12/10 15:41:03 INFO TaskSetManager: Starting task 10.0 in stage 3.0 (TID 13, 192.168.1.9, executor 1, partition 10, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:03 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 11) in 1755 ms on 192.168.1.9 (executor 1) (9/200)
20/12/10 15:41:05 INFO TaskSetManager: Starting task 11.0 in stage 3.0 (TID 14, 192.168.1.9, executor 2, partition 11, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:05 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 12) in 2133 ms on 192.168.1.9 (executor 2) (10/200)
20/12/10 15:41:05 INFO TaskSetManager: Starting task 12.0 in stage 3.0 (TID 15, 192.168.1.9, executor 1, partition 12, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:05 INFO TaskSetManager: Finished task 10.0 in stage 3.0 (TID 13) in 1653 ms on 192.168.1.9 (executor 1) (11/200)
20/12/10 15:41:08 INFO TaskSetManager: Starting task 13.0 in stage 3.0 (TID 16, 192.168.1.9, executor 2, partition 13, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:08 INFO TaskSetManager: Finished task 11.0 in stage 3.0 (TID 14) in 3268 ms on 192.168.1.9 (executor 2) (12/200)
20/12/10 15:41:08 INFO TaskSetManager: Starting task 14.0 in stage 3.0 (TID 17, 192.168.1.9, executor 1, partition 14, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:08 INFO TaskSetManager: Finished task 12.0 in stage 3.0 (TID 15) in 2945 ms on 192.168.1.9 (executor 1) (13/200)
20/12/10 15:41:10 INFO TaskSetManager: Starting task 15.0 in stage 3.0 (TID 18, 192.168.1.9, executor 2, partition 15, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:10 INFO TaskSetManager: Finished task 13.0 in stage 3.0 (TID 16) in 1915 ms on 192.168.1.9 (executor 2) (14/200)
20/12/10 15:41:11 INFO TaskSetManager: Starting task 16.0 in stage 3.0 (TID 19, 192.168.1.9, executor 2, partition 16, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:11 INFO TaskSetManager: Finished task 15.0 in stage 3.0 (TID 18) in 1624 ms on 192.168.1.9 (executor 2) (15/200)
20/12/10 15:41:12 INFO TaskSetManager: Finished task 14.0 in stage 3.0 (TID 17) in 4085 ms on 192.168.1.9 (executor 1) (16/200)
20/12/10 15:41:12 INFO TaskSetManager: Starting task 17.0 in stage 3.0 (TID 20, 192.168.1.9, executor 1, partition 17, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:13 INFO TaskSetManager: Starting task 18.0 in stage 3.0 (TID 21, 192.168.1.9, executor 1, partition 18, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:13 INFO TaskSetManager: Finished task 17.0 in stage 3.0 (TID 20) in 946 ms on 192.168.1.9 (executor 1) (17/200)
20/12/10 15:41:14 INFO TaskSetManager: Starting task 19.0 in stage 3.0 (TID 22, 192.168.1.9, executor 2, partition 19, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:14 INFO TaskSetManager: Finished task 16.0 in stage 3.0 (TID 19) in 2350 ms on 192.168.1.9 (executor 2) (18/200)
20/12/10 15:41:14 INFO TaskSetManager: Starting task 20.0 in stage 3.0 (TID 23, 192.168.1.9, executor 1, partition 20, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:14 INFO TaskSetManager: Finished task 18.0 in stage 3.0 (TID 21) in 952 ms on 192.168.1.9 (executor 1) (19/200)
20/12/10 15:41:15 INFO TaskSetManager: Starting task 21.0 in stage 3.0 (TID 24, 192.168.1.9, executor 1, partition 21, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:15 INFO TaskSetManager: Finished task 20.0 in stage 3.0 (TID 23) in 915 ms on 192.168.1.9 (executor 1) (20/200)
20/12/10 15:41:17 INFO TaskSetManager: Starting task 22.0 in stage 3.0 (TID 25, 192.168.1.9, executor 1, partition 22, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:17 INFO TaskSetManager: Finished task 21.0 in stage 3.0 (TID 24) in 2475 ms on 192.168.1.9 (executor 1) (21/200)
20/12/10 15:41:18 INFO TaskSetManager: Starting task 23.0 in stage 3.0 (TID 26, 192.168.1.9, executor 2, partition 23, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:18 INFO TaskSetManager: Finished task 19.0 in stage 3.0 (TID 22) in 4252 ms on 192.168.1.9 (executor 2) (22/200)
20/12/10 15:41:18 INFO TaskSetManager: Starting task 24.0 in stage 3.0 (TID 27, 192.168.1.9, executor 1, partition 24, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:18 INFO TaskSetManager: Finished task 22.0 in stage 3.0 (TID 25) in 893 ms on 192.168.1.9 (executor 1) (23/200)
20/12/10 15:41:20 INFO TaskSetManager: Finished task 24.0 in stage 3.0 (TID 27) in 1520 ms on 192.168.1.9 (executor 1) (24/200)
20/12/10 15:41:20 INFO TaskSetManager: Starting task 25.0 in stage 3.0 (TID 28, 192.168.1.9, executor 1, partition 25, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:20 INFO TaskSetManager: Starting task 26.0 in stage 3.0 (TID 29, 192.168.1.9, executor 1, partition 26, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:20 INFO TaskSetManager: Finished task 25.0 in stage 3.0 (TID 28) in 654 ms on 192.168.1.9 (executor 1) (25/200)
20/12/10 15:41:21 INFO TaskSetManager: Starting task 27.0 in stage 3.0 (TID 30, 192.168.1.9, executor 2, partition 27, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:21 INFO TaskSetManager: Finished task 23.0 in stage 3.0 (TID 26) in 2597 ms on 192.168.1.9 (executor 2) (26/200)
20/12/10 15:41:22 INFO TaskSetManager: Starting task 28.0 in stage 3.0 (TID 31, 192.168.1.9, executor 1, partition 28, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:22 INFO TaskSetManager: Finished task 26.0 in stage 3.0 (TID 29) in 1721 ms on 192.168.1.9 (executor 1) (27/200)
20/12/10 15:41:22 INFO TaskSetManager: Starting task 29.0 in stage 3.0 (TID 32, 192.168.1.9, executor 2, partition 29, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:22 INFO TaskSetManager: Finished task 27.0 in stage 3.0 (TID 30) in 1962 ms on 192.168.1.9 (executor 2) (28/200)
20/12/10 15:41:23 INFO TaskSetManager: Starting task 30.0 in stage 3.0 (TID 33, 192.168.1.9, executor 1, partition 30, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:23 INFO TaskSetManager: Finished task 28.0 in stage 3.0 (TID 31) in 761 ms on 192.168.1.9 (executor 1) (29/200)
20/12/10 15:41:24 INFO TaskSetManager: Starting task 31.0 in stage 3.0 (TID 34, 192.168.1.9, executor 2, partition 31, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:24 INFO TaskSetManager: Finished task 29.0 in stage 3.0 (TID 32) in 1460 ms on 192.168.1.9 (executor 2) (30/200)
20/12/10 15:41:26 INFO TaskSetManager: Starting task 32.0 in stage 3.0 (TID 35, 192.168.1.9, executor 1, partition 32, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:26 INFO TaskSetManager: Finished task 30.0 in stage 3.0 (TID 33) in 2606 ms on 192.168.1.9 (executor 1) (31/200)
20/12/10 15:41:26 INFO TaskSetManager: Starting task 33.0 in stage 3.0 (TID 36, 192.168.1.9, executor 2, partition 33, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:26 INFO TaskSetManager: Finished task 31.0 in stage 3.0 (TID 34) in 2211 ms on 192.168.1.9 (executor 2) (32/200)
20/12/10 15:41:29 INFO TaskSetManager: Starting task 34.0 in stage 3.0 (TID 37, 192.168.1.9, executor 1, partition 34, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:29 INFO TaskSetManager: Finished task 32.0 in stage 3.0 (TID 35) in 3275 ms on 192.168.1.9 (executor 1) (33/200)
20/12/10 15:41:30 INFO TaskSetManager: Starting task 35.0 in stage 3.0 (TID 38, 192.168.1.9, executor 2, partition 35, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:30 INFO TaskSetManager: Finished task 33.0 in stage 3.0 (TID 36) in 3445 ms on 192.168.1.9 (executor 2) (34/200)
20/12/10 15:41:30 INFO TaskSetManager: Starting task 36.0 in stage 3.0 (TID 39, 192.168.1.9, executor 2, partition 36, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:30 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.1.9:34211 in memory (size: 11.6 KiB, free: 5.8 GiB)
20/12/10 15:41:30 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.1.9:36951 in memory (size: 11.6 KiB, free: 912.1 MiB)
20/12/10 15:41:30 INFO TaskSetManager: Finished task 35.0 in stage 3.0 (TID 38) in 725 ms on 192.168.1.9 (executor 2) (35/200)
20/12/10 15:41:31 INFO TaskSetManager: Starting task 37.0 in stage 3.0 (TID 40, 192.168.1.9, executor 1, partition 37, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:31 INFO TaskSetManager: Finished task 34.0 in stage 3.0 (TID 37) in 2111 ms on 192.168.1.9 (executor 1) (36/200)
20/12/10 15:41:33 INFO TaskSetManager: Starting task 38.0 in stage 3.0 (TID 41, 192.168.1.9, executor 1, partition 38, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:33 INFO TaskSetManager: Finished task 37.0 in stage 3.0 (TID 40) in 1674 ms on 192.168.1.9 (executor 1) (37/200)
20/12/10 15:41:33 INFO TaskSetManager: Starting task 39.0 in stage 3.0 (TID 42, 192.168.1.9, executor 2, partition 39, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:33 INFO TaskSetManager: Finished task 36.0 in stage 3.0 (TID 39) in 2454 ms on 192.168.1.9 (executor 2) (38/200)
20/12/10 15:41:34 INFO TaskSetManager: Starting task 40.0 in stage 3.0 (TID 43, 192.168.1.9, executor 2, partition 40, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:34 INFO TaskSetManager: Finished task 39.0 in stage 3.0 (TID 42) in 1727 ms on 192.168.1.9 (executor 2) (39/200)
20/12/10 15:41:35 INFO TaskSetManager: Starting task 41.0 in stage 3.0 (TID 44, 192.168.1.9, executor 1, partition 41, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:35 INFO TaskSetManager: Finished task 38.0 in stage 3.0 (TID 41) in 2339 ms on 192.168.1.9 (executor 1) (40/200)
20/12/10 15:41:36 INFO TaskSetManager: Starting task 42.0 in stage 3.0 (TID 45, 192.168.1.9, executor 1, partition 42, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:36 INFO TaskSetManager: Finished task 41.0 in stage 3.0 (TID 44) in 607 ms on 192.168.1.9 (executor 1) (41/200)
20/12/10 15:41:36 INFO TaskSetManager: Starting task 43.0 in stage 3.0 (TID 46, 192.168.1.9, executor 1, partition 43, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:36 INFO TaskSetManager: Finished task 42.0 in stage 3.0 (TID 45) in 953 ms on 192.168.1.9 (executor 1) (42/200)
20/12/10 15:41:37 INFO TaskSetManager: Starting task 44.0 in stage 3.0 (TID 47, 192.168.1.9, executor 2, partition 44, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:37 INFO TaskSetManager: Finished task 40.0 in stage 3.0 (TID 43) in 2305 ms on 192.168.1.9 (executor 2) (43/200)
20/12/10 15:41:38 INFO TaskSetManager: Starting task 45.0 in stage 3.0 (TID 48, 192.168.1.9, executor 1, partition 45, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:38 INFO TaskSetManager: Finished task 43.0 in stage 3.0 (TID 46) in 1562 ms on 192.168.1.9 (executor 1) (44/200)
20/12/10 15:41:38 INFO TaskSetManager: Starting task 46.0 in stage 3.0 (TID 49, 192.168.1.9, executor 2, partition 46, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:38 INFO TaskSetManager: Finished task 44.0 in stage 3.0 (TID 47) in 1587 ms on 192.168.1.9 (executor 2) (45/200)
20/12/10 15:41:39 INFO TaskSetManager: Starting task 47.0 in stage 3.0 (TID 50, 192.168.1.9, executor 1, partition 47, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:39 INFO TaskSetManager: Finished task 45.0 in stage 3.0 (TID 48) in 663 ms on 192.168.1.9 (executor 1) (46/200)
20/12/10 15:41:39 INFO TaskSetManager: Starting task 48.0 in stage 3.0 (TID 51, 192.168.1.9, executor 2, partition 48, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:39 INFO TaskSetManager: Finished task 46.0 in stage 3.0 (TID 49) in 727 ms on 192.168.1.9 (executor 2) (47/200)
20/12/10 15:41:40 INFO TaskSetManager: Starting task 49.0 in stage 3.0 (TID 52, 192.168.1.9, executor 1, partition 49, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:40 INFO TaskSetManager: Finished task 47.0 in stage 3.0 (TID 50) in 1217 ms on 192.168.1.9 (executor 1) (48/200)
20/12/10 15:41:42 INFO TaskSetManager: Starting task 50.0 in stage 3.0 (TID 53, 192.168.1.9, executor 2, partition 50, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:42 INFO TaskSetManager: Finished task 48.0 in stage 3.0 (TID 51) in 2554 ms on 192.168.1.9 (executor 2) (49/200)
20/12/10 15:41:42 INFO TaskSetManager: Starting task 51.0 in stage 3.0 (TID 54, 192.168.1.9, executor 1, partition 51, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:42 INFO TaskSetManager: Finished task 49.0 in stage 3.0 (TID 52) in 2302 ms on 192.168.1.9 (executor 1) (50/200)
20/12/10 15:41:43 INFO TaskSetManager: Starting task 52.0 in stage 3.0 (TID 55, 192.168.1.9, executor 2, partition 52, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:43 INFO TaskSetManager: Finished task 50.0 in stage 3.0 (TID 53) in 1454 ms on 192.168.1.9 (executor 2) (51/200)
20/12/10 15:41:44 INFO TaskSetManager: Finished task 51.0 in stage 3.0 (TID 54) in 1791 ms on 192.168.1.9 (executor 1) (52/200)
20/12/10 15:41:44 INFO TaskSetManager: Starting task 53.0 in stage 3.0 (TID 56, 192.168.1.9, executor 1, partition 53, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:44 INFO TaskSetManager: Starting task 54.0 in stage 3.0 (TID 57, 192.168.1.9, executor 2, partition 54, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:44 INFO TaskSetManager: Finished task 52.0 in stage 3.0 (TID 55) in 1213 ms on 192.168.1.9 (executor 2) (53/200)
20/12/10 15:41:45 INFO TaskSetManager: Starting task 55.0 in stage 3.0 (TID 58, 192.168.1.9, executor 2, partition 55, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:45 INFO TaskSetManager: Finished task 54.0 in stage 3.0 (TID 57) in 1181 ms on 192.168.1.9 (executor 2) (54/200)
20/12/10 15:41:47 INFO TaskSetManager: Starting task 56.0 in stage 3.0 (TID 59, 192.168.1.9, executor 1, partition 56, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:47 INFO TaskSetManager: Finished task 53.0 in stage 3.0 (TID 56) in 3000 ms on 192.168.1.9 (executor 1) (55/200)
20/12/10 15:41:48 INFO TaskSetManager: Starting task 57.0 in stage 3.0 (TID 60, 192.168.1.9, executor 2, partition 57, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:48 INFO TaskSetManager: Finished task 55.0 in stage 3.0 (TID 58) in 2261 ms on 192.168.1.9 (executor 2) (56/200)
20/12/10 15:41:49 INFO TaskSetManager: Starting task 58.0 in stage 3.0 (TID 61, 192.168.1.9, executor 1, partition 58, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:49 INFO TaskSetManager: Finished task 56.0 in stage 3.0 (TID 59) in 1633 ms on 192.168.1.9 (executor 1) (57/200)
20/12/10 15:41:50 INFO TaskSetManager: Starting task 60.0 in stage 3.0 (TID 62, 192.168.1.9, executor 1, partition 60, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:50 INFO TaskSetManager: Finished task 58.0 in stage 3.0 (TID 61) in 931 ms on 192.168.1.9 (executor 1) (58/200)
20/12/10 15:41:51 INFO TaskSetManager: Starting task 61.0 in stage 3.0 (TID 63, 192.168.1.9, executor 2, partition 61, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:51 INFO TaskSetManager: Finished task 57.0 in stage 3.0 (TID 60) in 3041 ms on 192.168.1.9 (executor 2) (59/200)
20/12/10 15:41:51 INFO TaskSetManager: Starting task 62.0 in stage 3.0 (TID 64, 192.168.1.9, executor 1, partition 62, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:51 INFO TaskSetManager: Finished task 60.0 in stage 3.0 (TID 62) in 1612 ms on 192.168.1.9 (executor 1) (60/200)
20/12/10 15:41:52 INFO TaskSetManager: Starting task 63.0 in stage 3.0 (TID 65, 192.168.1.9, executor 1, partition 63, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:52 INFO TaskSetManager: Finished task 62.0 in stage 3.0 (TID 64) in 823 ms on 192.168.1.9 (executor 1) (61/200)
20/12/10 15:41:53 INFO TaskSetManager: Starting task 64.0 in stage 3.0 (TID 66, 192.168.1.9, executor 2, partition 64, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:53 INFO TaskSetManager: Finished task 61.0 in stage 3.0 (TID 63) in 1943 ms on 192.168.1.9 (executor 2) (62/200)
20/12/10 15:41:53 INFO TaskSetManager: Starting task 65.0 in stage 3.0 (TID 67, 192.168.1.9, executor 2, partition 65, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:53 INFO TaskSetManager: Finished task 64.0 in stage 3.0 (TID 66) in 673 ms on 192.168.1.9 (executor 2) (63/200)
20/12/10 15:41:53 INFO TaskSetManager: Starting task 66.0 in stage 3.0 (TID 68, 192.168.1.9, executor 1, partition 66, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:53 INFO TaskSetManager: Finished task 63.0 in stage 3.0 (TID 65) in 1423 ms on 192.168.1.9 (executor 1) (64/200)
20/12/10 15:41:55 INFO TaskSetManager: Starting task 67.0 in stage 3.0 (TID 69, 192.168.1.9, executor 2, partition 67, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:55 INFO TaskSetManager: Finished task 65.0 in stage 3.0 (TID 67) in 1949 ms on 192.168.1.9 (executor 2) (65/200)
20/12/10 15:41:56 INFO TaskSetManager: Starting task 69.0 in stage 3.0 (TID 70, 192.168.1.9, executor 1, partition 69, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:56 INFO TaskSetManager: Finished task 66.0 in stage 3.0 (TID 68) in 2503 ms on 192.168.1.9 (executor 1) (66/200)
20/12/10 15:41:56 INFO TaskSetManager: Starting task 70.0 in stage 3.0 (TID 71, 192.168.1.9, executor 2, partition 70, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:56 INFO TaskSetManager: Finished task 67.0 in stage 3.0 (TID 69) in 951 ms on 192.168.1.9 (executor 2) (67/200)
20/12/10 15:41:58 INFO TaskSetManager: Starting task 71.0 in stage 3.0 (TID 72, 192.168.1.9, executor 1, partition 71, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:58 INFO TaskSetManager: Finished task 69.0 in stage 3.0 (TID 70) in 1769 ms on 192.168.1.9 (executor 1) (68/200)
20/12/10 15:41:58 INFO TaskSetManager: Starting task 72.0 in stage 3.0 (TID 73, 192.168.1.9, executor 1, partition 72, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:58 INFO TaskSetManager: Finished task 71.0 in stage 3.0 (TID 72) in 599 ms on 192.168.1.9 (executor 1) (69/200)
20/12/10 15:41:59 INFO TaskSetManager: Starting task 73.0 in stage 3.0 (TID 74, 192.168.1.9, executor 2, partition 73, NODE_LOCAL, 7336 bytes)
20/12/10 15:41:59 INFO TaskSetManager: Finished task 70.0 in stage 3.0 (TID 71) in 2683 ms on 192.168.1.9 (executor 2) (70/200)
20/12/10 15:42:00 INFO TaskSetManager: Starting task 74.0 in stage 3.0 (TID 75, 192.168.1.9, executor 1, partition 74, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:00 INFO TaskSetManager: Finished task 72.0 in stage 3.0 (TID 73) in 1257 ms on 192.168.1.9 (executor 1) (71/200)
20/12/10 15:42:01 INFO TaskSetManager: Starting task 75.0 in stage 3.0 (TID 76, 192.168.1.9, executor 1, partition 75, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:01 INFO TaskSetManager: Finished task 74.0 in stage 3.0 (TID 75) in 1444 ms on 192.168.1.9 (executor 1) (72/200)
20/12/10 15:42:01 INFO TaskSetManager: Starting task 76.0 in stage 3.0 (TID 77, 192.168.1.9, executor 2, partition 76, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:01 INFO TaskSetManager: Finished task 73.0 in stage 3.0 (TID 74) in 2123 ms on 192.168.1.9 (executor 2) (73/200)
20/12/10 15:42:03 INFO TaskSetManager: Starting task 77.0 in stage 3.0 (TID 78, 192.168.1.9, executor 1, partition 77, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:03 INFO TaskSetManager: Finished task 75.0 in stage 3.0 (TID 76) in 2043 ms on 192.168.1.9 (executor 1) (74/200)
20/12/10 15:42:03 INFO TaskSetManager: Starting task 78.0 in stage 3.0 (TID 79, 192.168.1.9, executor 2, partition 78, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:03 INFO TaskSetManager: Finished task 76.0 in stage 3.0 (TID 77) in 2209 ms on 192.168.1.9 (executor 2) (75/200)
20/12/10 15:42:04 INFO TaskSetManager: Starting task 79.0 in stage 3.0 (TID 80, 192.168.1.9, executor 1, partition 79, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:04 INFO TaskSetManager: Finished task 77.0 in stage 3.0 (TID 78) in 1145 ms on 192.168.1.9 (executor 1) (76/200)
20/12/10 15:42:04 INFO TaskSetManager: Starting task 80.0 in stage 3.0 (TID 81, 192.168.1.9, executor 2, partition 80, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:04 INFO TaskSetManager: Finished task 78.0 in stage 3.0 (TID 79) in 1084 ms on 192.168.1.9 (executor 2) (77/200)
20/12/10 15:42:05 INFO TaskSetManager: Starting task 81.0 in stage 3.0 (TID 82, 192.168.1.9, executor 1, partition 81, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:05 INFO TaskSetManager: Finished task 79.0 in stage 3.0 (TID 80) in 1126 ms on 192.168.1.9 (executor 1) (78/200)
20/12/10 15:42:06 INFO TaskSetManager: Starting task 82.0 in stage 3.0 (TID 83, 192.168.1.9, executor 2, partition 82, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:06 INFO TaskSetManager: Finished task 80.0 in stage 3.0 (TID 81) in 1256 ms on 192.168.1.9 (executor 2) (79/200)
20/12/10 15:42:06 INFO TaskSetManager: Starting task 83.0 in stage 3.0 (TID 84, 192.168.1.9, executor 1, partition 83, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:06 INFO TaskSetManager: Finished task 81.0 in stage 3.0 (TID 82) in 652 ms on 192.168.1.9 (executor 1) (80/200)
20/12/10 15:42:07 INFO TaskSetManager: Starting task 84.0 in stage 3.0 (TID 85, 192.168.1.9, executor 2, partition 84, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:07 INFO TaskSetManager: Finished task 82.0 in stage 3.0 (TID 83) in 1114 ms on 192.168.1.9 (executor 2) (81/200)
20/12/10 15:42:08 INFO TaskSetManager: Starting task 85.0 in stage 3.0 (TID 86, 192.168.1.9, executor 2, partition 85, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:08 INFO TaskSetManager: Finished task 84.0 in stage 3.0 (TID 85) in 1290 ms on 192.168.1.9 (executor 2) (82/200)
20/12/10 15:42:09 INFO TaskSetManager: Starting task 86.0 in stage 3.0 (TID 87, 192.168.1.9, executor 1, partition 86, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:09 INFO TaskSetManager: Finished task 83.0 in stage 3.0 (TID 84) in 2710 ms on 192.168.1.9 (executor 1) (83/200)
20/12/10 15:42:11 INFO TaskSetManager: Starting task 87.0 in stage 3.0 (TID 88, 192.168.1.9, executor 1, partition 87, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:11 INFO TaskSetManager: Finished task 86.0 in stage 3.0 (TID 87) in 2165 ms on 192.168.1.9 (executor 1) (84/200)
20/12/10 15:42:11 INFO TaskSetManager: Starting task 88.0 in stage 3.0 (TID 89, 192.168.1.9, executor 2, partition 88, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:11 INFO TaskSetManager: Finished task 85.0 in stage 3.0 (TID 86) in 3028 ms on 192.168.1.9 (executor 2) (85/200)
20/12/10 15:42:13 INFO TaskSetManager: Starting task 89.0 in stage 3.0 (TID 90, 192.168.1.9, executor 1, partition 89, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:13 INFO TaskSetManager: Finished task 87.0 in stage 3.0 (TID 88) in 1708 ms on 192.168.1.9 (executor 1) (86/200)
20/12/10 15:42:14 INFO TaskSetManager: Starting task 90.0 in stage 3.0 (TID 91, 192.168.1.9, executor 2, partition 90, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:14 INFO TaskSetManager: Finished task 88.0 in stage 3.0 (TID 89) in 2789 ms on 192.168.1.9 (executor 2) (87/200)
20/12/10 15:42:14 INFO TaskSetManager: Starting task 91.0 in stage 3.0 (TID 92, 192.168.1.9, executor 1, partition 91, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:14 INFO TaskSetManager: Finished task 89.0 in stage 3.0 (TID 90) in 1949 ms on 192.168.1.9 (executor 1) (88/200)
20/12/10 15:42:15 INFO TaskSetManager: Starting task 93.0 in stage 3.0 (TID 93, 192.168.1.9, executor 2, partition 93, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:15 INFO TaskSetManager: Finished task 90.0 in stage 3.0 (TID 91) in 1071 ms on 192.168.1.9 (executor 2) (89/200)
20/12/10 15:42:16 INFO TaskSetManager: Starting task 94.0 in stage 3.0 (TID 94, 192.168.1.9, executor 2, partition 94, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:16 INFO TaskSetManager: Finished task 93.0 in stage 3.0 (TID 93) in 1413 ms on 192.168.1.9 (executor 2) (90/200)
20/12/10 15:42:17 INFO TaskSetManager: Starting task 95.0 in stage 3.0 (TID 95, 192.168.1.9, executor 2, partition 95, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:17 INFO TaskSetManager: Finished task 94.0 in stage 3.0 (TID 94) in 924 ms on 192.168.1.9 (executor 2) (91/200)
20/12/10 15:42:18 INFO TaskSetManager: Starting task 97.0 in stage 3.0 (TID 96, 192.168.1.9, executor 1, partition 97, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:18 INFO TaskSetManager: Finished task 91.0 in stage 3.0 (TID 92) in 3025 ms on 192.168.1.9 (executor 1) (92/200)
20/12/10 15:42:19 INFO TaskSetManager: Starting task 98.0 in stage 3.0 (TID 97, 192.168.1.9, executor 1, partition 98, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:19 INFO TaskSetManager: Finished task 97.0 in stage 3.0 (TID 96) in 1697 ms on 192.168.1.9 (executor 1) (93/200)
20/12/10 15:42:19 INFO TaskSetManager: Starting task 99.0 in stage 3.0 (TID 98, 192.168.1.9, executor 2, partition 99, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:19 INFO TaskSetManager: Finished task 95.0 in stage 3.0 (TID 95) in 2122 ms on 192.168.1.9 (executor 2) (94/200)
20/12/10 15:42:21 INFO TaskSetManager: Starting task 100.0 in stage 3.0 (TID 99, 192.168.1.9, executor 1, partition 100, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:21 INFO TaskSetManager: Finished task 98.0 in stage 3.0 (TID 97) in 1339 ms on 192.168.1.9 (executor 1) (95/200)
20/12/10 15:42:21 INFO TaskSetManager: Starting task 101.0 in stage 3.0 (TID 100, 192.168.1.9, executor 2, partition 101, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:21 INFO TaskSetManager: Finished task 99.0 in stage 3.0 (TID 98) in 1704 ms on 192.168.1.9 (executor 2) (96/200)
20/12/10 15:42:22 INFO TaskSetManager: Starting task 102.0 in stage 3.0 (TID 101, 192.168.1.9, executor 1, partition 102, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:22 INFO TaskSetManager: Finished task 100.0 in stage 3.0 (TID 99) in 1854 ms on 192.168.1.9 (executor 1) (97/200)
20/12/10 15:42:24 INFO TaskSetManager: Starting task 103.0 in stage 3.0 (TID 102, 192.168.1.9, executor 2, partition 103, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:24 INFO TaskSetManager: Finished task 101.0 in stage 3.0 (TID 100) in 2873 ms on 192.168.1.9 (executor 2) (98/200)
20/12/10 15:42:24 INFO TaskSetManager: Starting task 104.0 in stage 3.0 (TID 103, 192.168.1.9, executor 1, partition 104, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:24 INFO TaskSetManager: Finished task 102.0 in stage 3.0 (TID 101) in 2089 ms on 192.168.1.9 (executor 1) (99/200)
20/12/10 15:42:25 INFO TaskSetManager: Starting task 105.0 in stage 3.0 (TID 104, 192.168.1.9, executor 1, partition 105, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:25 INFO TaskSetManager: Finished task 104.0 in stage 3.0 (TID 103) in 979 ms on 192.168.1.9 (executor 1) (100/200)
20/12/10 15:42:26 INFO TaskSetManager: Starting task 106.0 in stage 3.0 (TID 105, 192.168.1.9, executor 1, partition 106, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:26 INFO TaskSetManager: Finished task 105.0 in stage 3.0 (TID 104) in 1028 ms on 192.168.1.9 (executor 1) (101/200)
20/12/10 15:42:27 INFO TaskSetManager: Starting task 107.0 in stage 3.0 (TID 106, 192.168.1.9, executor 2, partition 107, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:27 INFO TaskSetManager: Finished task 103.0 in stage 3.0 (TID 102) in 3141 ms on 192.168.1.9 (executor 2) (102/200)
20/12/10 15:42:29 INFO TaskSetManager: Starting task 108.0 in stage 3.0 (TID 107, 192.168.1.9, executor 2, partition 108, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:29 INFO TaskSetManager: Finished task 107.0 in stage 3.0 (TID 106) in 1843 ms on 192.168.1.9 (executor 2) (103/200)
20/12/10 15:42:29 INFO TaskSetManager: Starting task 109.0 in stage 3.0 (TID 108, 192.168.1.9, executor 1, partition 109, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:29 INFO TaskSetManager: Finished task 106.0 in stage 3.0 (TID 105) in 2512 ms on 192.168.1.9 (executor 1) (104/200)
20/12/10 15:42:30 INFO TaskSetManager: Starting task 110.0 in stage 3.0 (TID 109, 192.168.1.9, executor 1, partition 110, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:30 INFO TaskSetManager: Finished task 109.0 in stage 3.0 (TID 108) in 1501 ms on 192.168.1.9 (executor 1) (105/200)
20/12/10 15:42:31 INFO TaskSetManager: Starting task 111.0 in stage 3.0 (TID 110, 192.168.1.9, executor 2, partition 111, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:31 INFO TaskSetManager: Finished task 108.0 in stage 3.0 (TID 107) in 2149 ms on 192.168.1.9 (executor 2) (106/200)
20/12/10 15:42:32 INFO TaskSetManager: Starting task 112.0 in stage 3.0 (TID 111, 192.168.1.9, executor 1, partition 112, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:32 INFO TaskSetManager: Finished task 110.0 in stage 3.0 (TID 109) in 1275 ms on 192.168.1.9 (executor 1) (107/200)
20/12/10 15:42:32 INFO TaskSetManager: Starting task 113.0 in stage 3.0 (TID 112, 192.168.1.9, executor 2, partition 113, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:32 INFO TaskSetManager: Finished task 111.0 in stage 3.0 (TID 110) in 1218 ms on 192.168.1.9 (executor 2) (108/200)
20/12/10 15:42:36 INFO TaskSetManager: Starting task 114.0 in stage 3.0 (TID 113, 192.168.1.9, executor 2, partition 114, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:36 INFO TaskSetManager: Finished task 113.0 in stage 3.0 (TID 112) in 3298 ms on 192.168.1.9 (executor 2) (109/200)
20/12/10 15:42:36 INFO TaskSetManager: Starting task 115.0 in stage 3.0 (TID 114, 192.168.1.9, executor 1, partition 115, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:36 INFO TaskSetManager: Finished task 112.0 in stage 3.0 (TID 111) in 4111 ms on 192.168.1.9 (executor 1) (110/200)
20/12/10 15:42:37 INFO TaskSetManager: Starting task 116.0 in stage 3.0 (TID 115, 192.168.1.9, executor 2, partition 116, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:37 INFO TaskSetManager: Finished task 114.0 in stage 3.0 (TID 113) in 1546 ms on 192.168.1.9 (executor 2) (111/200)
20/12/10 15:42:38 INFO TaskSetManager: Starting task 117.0 in stage 3.0 (TID 116, 192.168.1.9, executor 1, partition 117, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:38 INFO TaskSetManager: Finished task 115.0 in stage 3.0 (TID 114) in 2458 ms on 192.168.1.9 (executor 1) (112/200)
20/12/10 15:42:39 INFO TaskSetManager: Starting task 118.0 in stage 3.0 (TID 117, 192.168.1.9, executor 2, partition 118, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:39 INFO TaskSetManager: Finished task 116.0 in stage 3.0 (TID 115) in 1606 ms on 192.168.1.9 (executor 2) (113/200)
20/12/10 15:42:40 INFO TaskSetManager: Starting task 119.0 in stage 3.0 (TID 118, 192.168.1.9, executor 1, partition 119, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:40 INFO TaskSetManager: Finished task 117.0 in stage 3.0 (TID 116) in 1278 ms on 192.168.1.9 (executor 1) (114/200)
20/12/10 15:42:40 INFO TaskSetManager: Starting task 120.0 in stage 3.0 (TID 119, 192.168.1.9, executor 1, partition 120, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:40 INFO TaskSetManager: Finished task 119.0 in stage 3.0 (TID 118) in 535 ms on 192.168.1.9 (executor 1) (115/200)
20/12/10 15:42:41 INFO TaskSetManager: Starting task 121.0 in stage 3.0 (TID 120, 192.168.1.9, executor 1, partition 121, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:41 INFO TaskSetManager: Finished task 120.0 in stage 3.0 (TID 119) in 1002 ms on 192.168.1.9 (executor 1) (116/200)
20/12/10 15:42:42 INFO TaskSetManager: Starting task 122.0 in stage 3.0 (TID 121, 192.168.1.9, executor 2, partition 122, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:42 INFO TaskSetManager: Finished task 118.0 in stage 3.0 (TID 117) in 2880 ms on 192.168.1.9 (executor 2) (117/200)
20/12/10 15:42:42 INFO TaskSetManager: Starting task 124.0 in stage 3.0 (TID 122, 192.168.1.9, executor 1, partition 124, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:42 INFO TaskSetManager: Finished task 121.0 in stage 3.0 (TID 120) in 1132 ms on 192.168.1.9 (executor 1) (118/200)
20/12/10 15:42:43 INFO TaskSetManager: Starting task 125.0 in stage 3.0 (TID 123, 192.168.1.9, executor 1, partition 125, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:43 INFO TaskSetManager: Finished task 124.0 in stage 3.0 (TID 122) in 1156 ms on 192.168.1.9 (executor 1) (119/200)
20/12/10 15:42:44 INFO TaskSetManager: Starting task 126.0 in stage 3.0 (TID 124, 192.168.1.9, executor 2, partition 126, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:44 INFO TaskSetManager: Finished task 122.0 in stage 3.0 (TID 121) in 2690 ms on 192.168.1.9 (executor 2) (120/200)
20/12/10 15:42:45 INFO TaskSetManager: Starting task 127.0 in stage 3.0 (TID 125, 192.168.1.9, executor 2, partition 127, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:45 INFO TaskSetManager: Finished task 126.0 in stage 3.0 (TID 124) in 924 ms on 192.168.1.9 (executor 2) (121/200)
20/12/10 15:42:46 INFO TaskSetManager: Starting task 128.0 in stage 3.0 (TID 126, 192.168.1.9, executor 1, partition 128, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:46 INFO TaskSetManager: Finished task 125.0 in stage 3.0 (TID 123) in 2240 ms on 192.168.1.9 (executor 1) (122/200)
20/12/10 15:42:46 INFO TaskSetManager: Starting task 129.0 in stage 3.0 (TID 127, 192.168.1.9, executor 2, partition 129, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:46 INFO TaskSetManager: Finished task 127.0 in stage 3.0 (TID 125) in 772 ms on 192.168.1.9 (executor 2) (123/200)
20/12/10 15:42:48 INFO TaskSetManager: Starting task 130.0 in stage 3.0 (TID 128, 192.168.1.9, executor 1, partition 130, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:48 INFO TaskSetManager: Finished task 128.0 in stage 3.0 (TID 126) in 2349 ms on 192.168.1.9 (executor 1) (124/200)
20/12/10 15:42:49 INFO TaskSetManager: Starting task 131.0 in stage 3.0 (TID 129, 192.168.1.9, executor 2, partition 131, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:49 INFO TaskSetManager: Finished task 129.0 in stage 3.0 (TID 127) in 2671 ms on 192.168.1.9 (executor 2) (125/200)
20/12/10 15:42:50 INFO TaskSetManager: Starting task 132.0 in stage 3.0 (TID 130, 192.168.1.9, executor 1, partition 132, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:50 INFO TaskSetManager: Finished task 130.0 in stage 3.0 (TID 128) in 2409 ms on 192.168.1.9 (executor 1) (126/200)
20/12/10 15:42:50 INFO TaskSetManager: Starting task 133.0 in stage 3.0 (TID 131, 192.168.1.9, executor 2, partition 133, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:50 INFO TaskSetManager: Finished task 131.0 in stage 3.0 (TID 129) in 1859 ms on 192.168.1.9 (executor 2) (127/200)
20/12/10 15:42:52 INFO TaskSetManager: Starting task 135.0 in stage 3.0 (TID 132, 192.168.1.9, executor 2, partition 135, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:52 INFO TaskSetManager: Finished task 133.0 in stage 3.0 (TID 131) in 1086 ms on 192.168.1.9 (executor 2) (128/200)
20/12/10 15:42:52 INFO TaskSetManager: Starting task 136.0 in stage 3.0 (TID 133, 192.168.1.9, executor 2, partition 136, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:52 INFO TaskSetManager: Finished task 135.0 in stage 3.0 (TID 132) in 918 ms on 192.168.1.9 (executor 2) (129/200)
20/12/10 15:42:53 INFO TaskSetManager: Starting task 137.0 in stage 3.0 (TID 134, 192.168.1.9, executor 1, partition 137, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:53 INFO TaskSetManager: Finished task 132.0 in stage 3.0 (TID 130) in 2815 ms on 192.168.1.9 (executor 1) (130/200)
20/12/10 15:42:54 INFO TaskSetManager: Starting task 138.0 in stage 3.0 (TID 135, 192.168.1.9, executor 2, partition 138, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:54 INFO TaskSetManager: Finished task 136.0 in stage 3.0 (TID 133) in 1378 ms on 192.168.1.9 (executor 2) (131/200)
20/12/10 15:42:55 INFO TaskSetManager: Starting task 139.0 in stage 3.0 (TID 136, 192.168.1.9, executor 1, partition 139, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:55 INFO TaskSetManager: Finished task 137.0 in stage 3.0 (TID 134) in 1867 ms on 192.168.1.9 (executor 1) (132/200)
20/12/10 15:42:56 INFO TaskSetManager: Starting task 140.0 in stage 3.0 (TID 137, 192.168.1.9, executor 2, partition 140, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:56 INFO TaskSetManager: Finished task 138.0 in stage 3.0 (TID 135) in 1790 ms on 192.168.1.9 (executor 2) (133/200)
20/12/10 15:42:56 INFO TaskSetManager: Starting task 141.0 in stage 3.0 (TID 138, 192.168.1.9, executor 1, partition 141, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:56 INFO TaskSetManager: Finished task 139.0 in stage 3.0 (TID 136) in 1050 ms on 192.168.1.9 (executor 1) (134/200)
20/12/10 15:42:58 INFO TaskSetManager: Starting task 142.0 in stage 3.0 (TID 139, 192.168.1.9, executor 1, partition 142, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:58 INFO TaskSetManager: Finished task 141.0 in stage 3.0 (TID 138) in 1346 ms on 192.168.1.9 (executor 1) (135/200)
20/12/10 15:42:58 INFO TaskSetManager: Starting task 143.0 in stage 3.0 (TID 140, 192.168.1.9, executor 2, partition 143, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:58 INFO TaskSetManager: Finished task 140.0 in stage 3.0 (TID 137) in 2367 ms on 192.168.1.9 (executor 2) (136/200)
20/12/10 15:42:59 INFO TaskSetManager: Starting task 144.0 in stage 3.0 (TID 141, 192.168.1.9, executor 2, partition 144, NODE_LOCAL, 7336 bytes)
20/12/10 15:42:59 INFO TaskSetManager: Finished task 143.0 in stage 3.0 (TID 140) in 1281 ms on 192.168.1.9 (executor 2) (137/200)
20/12/10 15:43:00 INFO TaskSetManager: Starting task 145.0 in stage 3.0 (TID 142, 192.168.1.9, executor 1, partition 145, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:00 INFO TaskSetManager: Finished task 142.0 in stage 3.0 (TID 139) in 2474 ms on 192.168.1.9 (executor 1) (138/200)
20/12/10 15:43:00 INFO TaskSetManager: Starting task 146.0 in stage 3.0 (TID 143, 192.168.1.9, executor 2, partition 146, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:00 INFO TaskSetManager: Finished task 144.0 in stage 3.0 (TID 141) in 1146 ms on 192.168.1.9 (executor 2) (139/200)
20/12/10 15:43:02 INFO TaskSetManager: Starting task 147.0 in stage 3.0 (TID 144, 192.168.1.9, executor 1, partition 147, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:02 INFO TaskSetManager: Finished task 145.0 in stage 3.0 (TID 142) in 1914 ms on 192.168.1.9 (executor 1) (140/200)
20/12/10 15:43:02 INFO TaskSetManager: Starting task 150.0 in stage 3.0 (TID 145, 192.168.1.9, executor 2, partition 150, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:02 INFO TaskSetManager: Finished task 146.0 in stage 3.0 (TID 143) in 1638 ms on 192.168.1.9 (executor 2) (141/200)
20/12/10 15:43:04 INFO TaskSetManager: Starting task 151.0 in stage 3.0 (TID 146, 192.168.1.9, executor 2, partition 151, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:04 INFO TaskSetManager: Finished task 150.0 in stage 3.0 (TID 145) in 2056 ms on 192.168.1.9 (executor 2) (142/200)
20/12/10 15:43:04 INFO TaskSetManager: Starting task 152.0 in stage 3.0 (TID 147, 192.168.1.9, executor 1, partition 152, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:04 INFO TaskSetManager: Finished task 147.0 in stage 3.0 (TID 144) in 2310 ms on 192.168.1.9 (executor 1) (143/200)
20/12/10 15:43:06 INFO TaskSetManager: Starting task 153.0 in stage 3.0 (TID 148, 192.168.1.9, executor 2, partition 153, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:06 INFO TaskSetManager: Finished task 151.0 in stage 3.0 (TID 146) in 1970 ms on 192.168.1.9 (executor 2) (144/200)
20/12/10 15:43:07 INFO TaskSetManager: Starting task 154.0 in stage 3.0 (TID 149, 192.168.1.9, executor 1, partition 154, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:07 INFO TaskSetManager: Finished task 152.0 in stage 3.0 (TID 147) in 2367 ms on 192.168.1.9 (executor 1) (145/200)
20/12/10 15:43:08 INFO TaskSetManager: Starting task 155.0 in stage 3.0 (TID 150, 192.168.1.9, executor 1, partition 155, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:08 INFO TaskSetManager: Finished task 154.0 in stage 3.0 (TID 149) in 1270 ms on 192.168.1.9 (executor 1) (146/200)
20/12/10 15:43:09 INFO TaskSetManager: Starting task 156.0 in stage 3.0 (TID 151, 192.168.1.9, executor 2, partition 156, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:09 INFO TaskSetManager: Finished task 153.0 in stage 3.0 (TID 148) in 2958 ms on 192.168.1.9 (executor 2) (147/200)
20/12/10 15:43:11 INFO TaskSetManager: Starting task 157.0 in stage 3.0 (TID 152, 192.168.1.9, executor 1, partition 157, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:11 INFO TaskSetManager: Finished task 155.0 in stage 3.0 (TID 150) in 3017 ms on 192.168.1.9 (executor 1) (148/200)
20/12/10 15:43:12 INFO TaskSetManager: Starting task 158.0 in stage 3.0 (TID 153, 192.168.1.9, executor 2, partition 158, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:12 INFO TaskSetManager: Finished task 156.0 in stage 3.0 (TID 151) in 2606 ms on 192.168.1.9 (executor 2) (149/200)
20/12/10 15:43:13 INFO TaskSetManager: Starting task 159.0 in stage 3.0 (TID 154, 192.168.1.9, executor 1, partition 159, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:13 INFO TaskSetManager: Finished task 157.0 in stage 3.0 (TID 152) in 2078 ms on 192.168.1.9 (executor 1) (150/200)
20/12/10 15:43:13 INFO TaskSetManager: Starting task 160.0 in stage 3.0 (TID 155, 192.168.1.9, executor 2, partition 160, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:13 INFO TaskSetManager: Finished task 158.0 in stage 3.0 (TID 153) in 1432 ms on 192.168.1.9 (executor 2) (151/200)
20/12/10 15:43:14 INFO TaskSetManager: Starting task 161.0 in stage 3.0 (TID 156, 192.168.1.9, executor 1, partition 161, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:14 INFO TaskSetManager: Finished task 159.0 in stage 3.0 (TID 154) in 1158 ms on 192.168.1.9 (executor 1) (152/200)
20/12/10 15:43:14 INFO TaskSetManager: Starting task 162.0 in stage 3.0 (TID 157, 192.168.1.9, executor 2, partition 162, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:14 INFO TaskSetManager: Finished task 160.0 in stage 3.0 (TID 155) in 1304 ms on 192.168.1.9 (executor 2) (153/200)
20/12/10 15:43:15 INFO TaskSetManager: Starting task 163.0 in stage 3.0 (TID 158, 192.168.1.9, executor 2, partition 163, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:15 INFO TaskSetManager: Finished task 162.0 in stage 3.0 (TID 157) in 960 ms on 192.168.1.9 (executor 2) (154/200)
20/12/10 15:43:16 INFO TaskSetManager: Starting task 164.0 in stage 3.0 (TID 159, 192.168.1.9, executor 1, partition 164, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:16 INFO TaskSetManager: Finished task 161.0 in stage 3.0 (TID 156) in 1706 ms on 192.168.1.9 (executor 1) (155/200)
20/12/10 15:43:18 INFO TaskSetManager: Starting task 165.0 in stage 3.0 (TID 160, 192.168.1.9, executor 2, partition 165, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:18 INFO TaskSetManager: Finished task 163.0 in stage 3.0 (TID 158) in 2659 ms on 192.168.1.9 (executor 2) (156/200)
20/12/10 15:43:19 INFO TaskSetManager: Starting task 166.0 in stage 3.0 (TID 161, 192.168.1.9, executor 1, partition 166, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:19 INFO TaskSetManager: Finished task 164.0 in stage 3.0 (TID 159) in 3628 ms on 192.168.1.9 (executor 1) (157/200)
20/12/10 15:43:20 INFO TaskSetManager: Starting task 167.0 in stage 3.0 (TID 162, 192.168.1.9, executor 2, partition 167, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:20 INFO TaskSetManager: Finished task 165.0 in stage 3.0 (TID 160) in 2166 ms on 192.168.1.9 (executor 2) (158/200)
20/12/10 15:43:21 INFO TaskSetManager: Starting task 168.0 in stage 3.0 (TID 163, 192.168.1.9, executor 1, partition 168, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:21 INFO TaskSetManager: Finished task 166.0 in stage 3.0 (TID 161) in 1223 ms on 192.168.1.9 (executor 1) (159/200)
20/12/10 15:43:21 INFO TaskSetManager: Starting task 169.0 in stage 3.0 (TID 164, 192.168.1.9, executor 2, partition 169, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:21 INFO TaskSetManager: Finished task 167.0 in stage 3.0 (TID 162) in 1225 ms on 192.168.1.9 (executor 2) (160/200)
20/12/10 15:43:23 INFO TaskSetManager: Starting task 170.0 in stage 3.0 (TID 165, 192.168.1.9, executor 2, partition 170, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:23 INFO TaskSetManager: Finished task 169.0 in stage 3.0 (TID 164) in 1513 ms on 192.168.1.9 (executor 2) (161/200)
20/12/10 15:43:25 INFO TaskSetManager: Starting task 171.0 in stage 3.0 (TID 166, 192.168.1.9, executor 1, partition 171, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:25 INFO TaskSetManager: Finished task 168.0 in stage 3.0 (TID 163) in 4135 ms on 192.168.1.9 (executor 1) (162/200)
20/12/10 15:43:25 INFO TaskSetManager: Starting task 172.0 in stage 3.0 (TID 167, 192.168.1.9, executor 2, partition 172, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:25 INFO TaskSetManager: Finished task 170.0 in stage 3.0 (TID 165) in 2433 ms on 192.168.1.9 (executor 2) (163/200)
20/12/10 15:43:27 INFO TaskSetManager: Starting task 173.0 in stage 3.0 (TID 168, 192.168.1.9, executor 2, partition 173, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:27 INFO TaskSetManager: Finished task 172.0 in stage 3.0 (TID 167) in 1855 ms on 192.168.1.9 (executor 2) (164/200)
20/12/10 15:43:27 INFO TaskSetManager: Starting task 174.0 in stage 3.0 (TID 169, 192.168.1.9, executor 1, partition 174, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:27 INFO TaskSetManager: Finished task 171.0 in stage 3.0 (TID 166) in 2602 ms on 192.168.1.9 (executor 1) (165/200)
20/12/10 15:43:29 INFO TaskSetManager: Finished task 174.0 in stage 3.0 (TID 169) in 2006 ms on 192.168.1.9 (executor 1) (166/200)
20/12/10 15:43:29 INFO TaskSetManager: Starting task 175.0 in stage 3.0 (TID 170, 192.168.1.9, executor 1, partition 175, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:30 INFO TaskSetManager: Starting task 176.0 in stage 3.0 (TID 171, 192.168.1.9, executor 2, partition 176, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:30 INFO TaskSetManager: Finished task 173.0 in stage 3.0 (TID 168) in 3244 ms on 192.168.1.9 (executor 2) (167/200)
20/12/10 15:43:31 INFO TaskSetManager: Starting task 177.0 in stage 3.0 (TID 172, 192.168.1.9, executor 1, partition 177, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:31 INFO TaskSetManager: Finished task 175.0 in stage 3.0 (TID 170) in 1402 ms on 192.168.1.9 (executor 1) (168/200)
20/12/10 15:43:31 INFO TaskSetManager: Starting task 178.0 in stage 3.0 (TID 173, 192.168.1.9, executor 2, partition 178, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:31 INFO TaskSetManager: Finished task 176.0 in stage 3.0 (TID 171) in 596 ms on 192.168.1.9 (executor 2) (169/200)
20/12/10 15:43:32 INFO TaskSetManager: Starting task 179.0 in stage 3.0 (TID 174, 192.168.1.9, executor 2, partition 179, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:32 INFO TaskSetManager: Finished task 178.0 in stage 3.0 (TID 173) in 1137 ms on 192.168.1.9 (executor 2) (170/200)
20/12/10 15:43:33 INFO TaskSetManager: Starting task 181.0 in stage 3.0 (TID 175, 192.168.1.9, executor 1, partition 181, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:33 INFO TaskSetManager: Finished task 177.0 in stage 3.0 (TID 172) in 1858 ms on 192.168.1.9 (executor 1) (171/200)
20/12/10 15:43:34 INFO TaskSetManager: Starting task 182.0 in stage 3.0 (TID 176, 192.168.1.9, executor 2, partition 182, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:34 INFO TaskSetManager: Finished task 179.0 in stage 3.0 (TID 174) in 1605 ms on 192.168.1.9 (executor 2) (172/200)
20/12/10 15:43:34 INFO TaskSetManager: Starting task 183.0 in stage 3.0 (TID 177, 192.168.1.9, executor 1, partition 183, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:34 INFO TaskSetManager: Finished task 181.0 in stage 3.0 (TID 175) in 1226 ms on 192.168.1.9 (executor 1) (173/200)
20/12/10 15:43:35 INFO TaskSetManager: Starting task 184.0 in stage 3.0 (TID 178, 192.168.1.9, executor 2, partition 184, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:35 INFO TaskSetManager: Finished task 182.0 in stage 3.0 (TID 176) in 1472 ms on 192.168.1.9 (executor 2) (174/200)
20/12/10 15:43:35 INFO TaskSetManager: Starting task 185.0 in stage 3.0 (TID 179, 192.168.1.9, executor 1, partition 185, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:35 INFO TaskSetManager: Finished task 183.0 in stage 3.0 (TID 177) in 1623 ms on 192.168.1.9 (executor 1) (175/200)
20/12/10 15:43:37 INFO TaskSetManager: Starting task 187.0 in stage 3.0 (TID 180, 192.168.1.9, executor 1, partition 187, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:37 INFO TaskSetManager: Finished task 185.0 in stage 3.0 (TID 179) in 1230 ms on 192.168.1.9 (executor 1) (176/200)
20/12/10 15:43:38 INFO TaskSetManager: Starting task 188.0 in stage 3.0 (TID 181, 192.168.1.9, executor 2, partition 188, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:38 INFO TaskSetManager: Finished task 184.0 in stage 3.0 (TID 178) in 2737 ms on 192.168.1.9 (executor 2) (177/200)
20/12/10 15:43:38 INFO TaskSetManager: Starting task 189.0 in stage 3.0 (TID 182, 192.168.1.9, executor 1, partition 189, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:38 INFO TaskSetManager: Finished task 187.0 in stage 3.0 (TID 180) in 1664 ms on 192.168.1.9 (executor 1) (178/200)
20/12/10 15:43:39 INFO TaskSetManager: Starting task 190.0 in stage 3.0 (TID 183, 192.168.1.9, executor 2, partition 190, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:39 INFO TaskSetManager: Finished task 188.0 in stage 3.0 (TID 181) in 1132 ms on 192.168.1.9 (executor 2) (179/200)
20/12/10 15:43:40 INFO TaskSetManager: Starting task 192.0 in stage 3.0 (TID 184, 192.168.1.9, executor 1, partition 192, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:40 INFO TaskSetManager: Finished task 189.0 in stage 3.0 (TID 182) in 1619 ms on 192.168.1.9 (executor 1) (180/200)
20/12/10 15:43:40 INFO TaskSetManager: Starting task 193.0 in stage 3.0 (TID 185, 192.168.1.9, executor 2, partition 193, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:40 INFO TaskSetManager: Finished task 190.0 in stage 3.0 (TID 183) in 1334 ms on 192.168.1.9 (executor 2) (181/200)
20/12/10 15:43:41 INFO TaskSetManager: Starting task 194.0 in stage 3.0 (TID 186, 192.168.1.9, executor 1, partition 194, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:41 INFO TaskSetManager: Finished task 192.0 in stage 3.0 (TID 184) in 1175 ms on 192.168.1.9 (executor 1) (182/200)
20/12/10 15:43:42 INFO TaskSetManager: Starting task 195.0 in stage 3.0 (TID 187, 192.168.1.9, executor 2, partition 195, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:42 INFO TaskSetManager: Finished task 193.0 in stage 3.0 (TID 185) in 1159 ms on 192.168.1.9 (executor 2) (183/200)
20/12/10 15:43:43 INFO TaskSetManager: Starting task 196.0 in stage 3.0 (TID 188, 192.168.1.9, executor 2, partition 196, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:43 INFO TaskSetManager: Finished task 195.0 in stage 3.0 (TID 187) in 1015 ms on 192.168.1.9 (executor 2) (184/200)
20/12/10 15:43:43 INFO TaskSetManager: Starting task 198.0 in stage 3.0 (TID 189, 192.168.1.9, executor 1, partition 198, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:43 INFO TaskSetManager: Finished task 194.0 in stage 3.0 (TID 186) in 2007 ms on 192.168.1.9 (executor 1) (185/200)
20/12/10 15:43:44 INFO TaskSetManager: Starting task 199.0 in stage 3.0 (TID 190, 192.168.1.9, executor 2, partition 199, NODE_LOCAL, 7336 bytes)
20/12/10 15:43:44 INFO TaskSetManager: Finished task 196.0 in stage 3.0 (TID 188) in 1074 ms on 192.168.1.9 (executor 2) (186/200)
20/12/10 15:43:46 INFO TaskSetManager: Starting task 59.0 in stage 3.0 (TID 191, 192.168.1.9, executor 1, partition 59, PROCESS_LOCAL, 7336 bytes)
20/12/10 15:43:46 INFO TaskSetManager: Finished task 198.0 in stage 3.0 (TID 189) in 2824 ms on 192.168.1.9 (executor 1) (187/200)
20/12/10 15:43:46 INFO TaskSetManager: Starting task 68.0 in stage 3.0 (TID 192, 192.168.1.9, executor 2, partition 68, PROCESS_LOCAL, 7336 bytes)
20/12/10 15:43:46 INFO TaskSetManager: Finished task 199.0 in stage 3.0 (TID 190) in 2397 ms on 192.168.1.9 (executor 2) (188/200)
20/12/10 15:43:46 INFO TaskSetManager: Starting task 92.0 in stage 3.0 (TID 193, 192.168.1.9, executor 1, partition 92, PROCESS_LOCAL, 7336 bytes)
20/12/10 15:43:46 INFO TaskSetManager: Finished task 59.0 in stage 3.0 (TID 191) in 154 ms on 192.168.1.9 (executor 1) (189/200)
20/12/10 15:43:46 INFO TaskSetManager: Starting task 96.0 in stage 3.0 (TID 194, 192.168.1.9, executor 2, partition 96, PROCESS_LOCAL, 7336 bytes)
20/12/10 15:43:46 INFO TaskSetManager: Finished task 68.0 in stage 3.0 (TID 192) in 142 ms on 192.168.1.9 (executor 2) (190/200)
20/12/10 15:43:46 INFO TaskSetManager: Starting task 123.0 in stage 3.0 (TID 195, 192.168.1.9, executor 1, partition 123, PROCESS_LOCAL, 7336 bytes)
20/12/10 15:43:46 INFO TaskSetManager: Finished task 92.0 in stage 3.0 (TID 193) in 141 ms on 192.168.1.9 (executor 1) (191/200)
20/12/10 15:43:46 INFO TaskSetManager: Starting task 134.0 in stage 3.0 (TID 196, 192.168.1.9, executor 2, partition 134, PROCESS_LOCAL, 7336 bytes)
20/12/10 15:43:46 INFO TaskSetManager: Finished task 96.0 in stage 3.0 (TID 194) in 120 ms on 192.168.1.9 (executor 2) (192/200)
20/12/10 15:43:46 INFO TaskSetManager: Starting task 148.0 in stage 3.0 (TID 197, 192.168.1.9, executor 1, partition 148, PROCESS_LOCAL, 7336 bytes)
20/12/10 15:43:46 INFO TaskSetManager: Finished task 123.0 in stage 3.0 (TID 195) in 156 ms on 192.168.1.9 (executor 1) (193/200)
20/12/10 15:43:46 INFO TaskSetManager: Starting task 149.0 in stage 3.0 (TID 198, 192.168.1.9, executor 2, partition 149, PROCESS_LOCAL, 7336 bytes)
20/12/10 15:43:46 INFO TaskSetManager: Finished task 134.0 in stage 3.0 (TID 196) in 149 ms on 192.168.1.9 (executor 2) (194/200)
20/12/10 15:43:47 INFO TaskSetManager: Starting task 180.0 in stage 3.0 (TID 199, 192.168.1.9, executor 2, partition 180, PROCESS_LOCAL, 7336 bytes)
20/12/10 15:43:47 INFO TaskSetManager: Finished task 149.0 in stage 3.0 (TID 198) in 125 ms on 192.168.1.9 (executor 2) (195/200)
20/12/10 15:43:47 INFO TaskSetManager: Starting task 186.0 in stage 3.0 (TID 200, 192.168.1.9, executor 1, partition 186, PROCESS_LOCAL, 7336 bytes)
20/12/10 15:43:47 INFO TaskSetManager: Finished task 148.0 in stage 3.0 (TID 197) in 131 ms on 192.168.1.9 (executor 1) (196/200)
20/12/10 15:43:47 INFO TaskSetManager: Starting task 191.0 in stage 3.0 (TID 201, 192.168.1.9, executor 2, partition 191, PROCESS_LOCAL, 7336 bytes)
20/12/10 15:43:47 INFO TaskSetManager: Finished task 180.0 in stage 3.0 (TID 199) in 183 ms on 192.168.1.9 (executor 2) (197/200)
20/12/10 15:43:47 INFO TaskSetManager: Starting task 197.0 in stage 3.0 (TID 202, 192.168.1.9, executor 1, partition 197, PROCESS_LOCAL, 7336 bytes)
20/12/10 15:43:47 INFO TaskSetManager: Finished task 186.0 in stage 3.0 (TID 200) in 199 ms on 192.168.1.9 (executor 1) (198/200)
20/12/10 15:43:47 INFO TaskSetManager: Finished task 191.0 in stage 3.0 (TID 201) in 123 ms on 192.168.1.9 (executor 2) (199/200)
20/12/10 15:43:47 INFO TaskSetManager: Finished task 197.0 in stage 3.0 (TID 202) in 119 ms on 192.168.1.9 (executor 1) (200/200)
20/12/10 15:43:47 INFO YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
20/12/10 15:43:47 INFO DAGScheduler: ResultStage 3 (toPandas at /tmp/spark-8bc0eb3c-92a7-4e21-8a4f-4415f689a7de/userFiles-5aa891bb-63e0-48b5-bc49-60ffed296deb/darima.zip/darima/dlsa.py:22) finished in 183.967 s
20/12/10 15:43:47 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
20/12/10 15:43:47 INFO YarnScheduler: Killing all running tasks in stage 3: Stage finished
20/12/10 15:43:47 INFO DAGScheduler: Job 1 finished: toPandas at /tmp/spark-8bc0eb3c-92a7-4e21-8a4f-4415f689a7de/userFiles-5aa891bb-63e0-48b5-bc49-60ffed296deb/darima.zip/darima/dlsa.py:22, took 187.728571 s
20/12/10 15:43:48 INFO FileSourceStrategy: Pruning directories with: 
20/12/10 15:43:48 INFO FileSourceStrategy: Pushed Filters: 
20/12/10 15:43:48 INFO FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, t#1,traffic_volume#0)
20/12/10 15:43:48 INFO FileSourceStrategy: Output Data Schema: struct<traffic_volume: double, t: string>
20/12/10 15:43:48 INFO CodeGenerator: Code generated in 14.911248 ms
20/12/10 15:43:48 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 177.4 KiB, free 5.8 GiB)
20/12/10 15:43:48 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 28.7 KiB, free 5.8 GiB)
20/12/10 15:43:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.1.9:34211 (size: 28.7 KiB, free: 5.8 GiB)
20/12/10 15:43:48 INFO SparkContext: Created broadcast 6 from toPandas at /home/bsuconn/Documents/Fall_2020/STAT_5825/Project/darima-master/run_darima.py:207
20/12/10 15:43:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 15:43:48 INFO SparkContext: Starting job: toPandas at /home/bsuconn/Documents/Fall_2020/STAT_5825/Project/darima-master/run_darima.py:207
20/12/10 15:43:48 INFO DAGScheduler: Got job 2 (toPandas at /home/bsuconn/Documents/Fall_2020/STAT_5825/Project/darima-master/run_darima.py:207) with 1 output partitions
20/12/10 15:43:48 INFO DAGScheduler: Final stage: ResultStage 4 (toPandas at /home/bsuconn/Documents/Fall_2020/STAT_5825/Project/darima-master/run_darima.py:207)
20/12/10 15:43:48 INFO DAGScheduler: Parents of final stage: List()
20/12/10 15:43:48 INFO DAGScheduler: Missing parents: List()
20/12/10 15:43:48 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[25] at toPandas at /home/bsuconn/Documents/Fall_2020/STAT_5825/Project/darima-master/run_darima.py:207), which has no missing parents
20/12/10 15:43:48 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 21.7 KiB, free 5.8 GiB)
20/12/10 15:43:48 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.4 KiB, free 5.8 GiB)
20/12/10 15:43:48 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.1.9:34211 (size: 10.4 KiB, free: 5.8 GiB)
20/12/10 15:43:48 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1223
20/12/10 15:43:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[25] at toPandas at /home/bsuconn/Documents/Fall_2020/STAT_5825/Project/darima-master/run_darima.py:207) (first 15 tasks are for partitions Vector(0))
20/12/10 15:43:48 INFO YarnScheduler: Adding task set 4.0 with 1 tasks
20/12/10 15:43:48 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 203, 192.168.1.9, executor 1, partition 0, NODE_LOCAL, 7790 bytes)
20/12/10 15:43:48 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.1.9:44815 (size: 10.4 KiB, free: 912.1 MiB)
20/12/10 15:43:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.1.9:44815 (size: 28.7 KiB, free: 912.1 MiB)
20/12/10 15:43:49 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 203) in 918 ms on 192.168.1.9 (executor 1) (1/1)
20/12/10 15:43:49 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
20/12/10 15:43:49 INFO DAGScheduler: ResultStage 4 (toPandas at /home/bsuconn/Documents/Fall_2020/STAT_5825/Project/darima-master/run_darima.py:207) finished in 0.932 s
20/12/10 15:43:49 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
20/12/10 15:43:49 INFO YarnScheduler: Killing all running tasks in stage 4: Stage finished
20/12/10 15:43:49 INFO DAGScheduler: Job 2 finished: toPandas at /home/bsuconn/Documents/Fall_2020/STAT_5825/Project/darima-master/run_darima.py:207, took 0.937684 s
20/12/10 15:43:54 INFO FileSourceStrategy: Pruning directories with: 
20/12/10 15:43:54 INFO FileSourceStrategy: Pushed Filters: 
20/12/10 15:43:54 INFO FileSourceStrategy: Post-Scan Filters: 
20/12/10 15:43:54 INFO FileSourceStrategy: Output Data Schema: struct<traffic_volume: double, t: string>
20/12/10 15:43:54 INFO CodeGenerator: Code generated in 15.172833 ms
20/12/10 15:43:54 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 177.4 KiB, free 5.8 GiB)
20/12/10 15:43:54 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 28.7 KiB, free 5.8 GiB)
20/12/10 15:43:54 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.1.9:34211 (size: 28.7 KiB, free: 5.8 GiB)
20/12/10 15:43:54 INFO SparkContext: Created broadcast 8 from toPandas at /home/bsuconn/Documents/Fall_2020/STAT_5825/Project/darima-master/run_darima.py:223
20/12/10 15:43:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 15:43:54 INFO SparkContext: Starting job: toPandas at /home/bsuconn/Documents/Fall_2020/STAT_5825/Project/darima-master/run_darima.py:223
20/12/10 15:43:54 INFO DAGScheduler: Got job 3 (toPandas at /home/bsuconn/Documents/Fall_2020/STAT_5825/Project/darima-master/run_darima.py:223) with 1 output partitions
20/12/10 15:43:54 INFO DAGScheduler: Final stage: ResultStage 5 (toPandas at /home/bsuconn/Documents/Fall_2020/STAT_5825/Project/darima-master/run_darima.py:223)
20/12/10 15:43:54 INFO DAGScheduler: Parents of final stage: List()
20/12/10 15:43:54 INFO DAGScheduler: Missing parents: List()
20/12/10 15:43:54 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at toPandas at /home/bsuconn/Documents/Fall_2020/STAT_5825/Project/darima-master/run_darima.py:223), which has no missing parents
20/12/10 15:43:54 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 12.3 KiB, free 5.8 GiB)
20/12/10 15:43:54 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 5.8 GiB)
20/12/10 15:43:54 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.1.9:34211 (size: 6.3 KiB, free: 5.8 GiB)
20/12/10 15:43:54 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1223
20/12/10 15:43:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at toPandas at /home/bsuconn/Documents/Fall_2020/STAT_5825/Project/darima-master/run_darima.py:223) (first 15 tasks are for partitions Vector(0))
20/12/10 15:43:54 INFO YarnScheduler: Adding task set 5.0 with 1 tasks
20/12/10 15:43:54 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 204, 192.168.1.9, executor 1, partition 0, NODE_LOCAL, 7789 bytes)
20/12/10 15:43:54 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.1.9:44815 (size: 6.3 KiB, free: 912.1 MiB)
20/12/10 15:43:54 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.1.9:44815 (size: 28.7 KiB, free: 912.1 MiB)
20/12/10 15:43:54 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 204) in 128 ms on 192.168.1.9 (executor 1) (1/1)
20/12/10 15:43:54 INFO YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool 
20/12/10 15:43:54 INFO DAGScheduler: ResultStage 5 (toPandas at /home/bsuconn/Documents/Fall_2020/STAT_5825/Project/darima-master/run_darima.py:223) finished in 0.139 s
20/12/10 15:43:54 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
20/12/10 15:43:54 INFO YarnScheduler: Killing all running tasks in stage 5: Stage finished
20/12/10 15:43:54 INFO DAGScheduler: Job 3 finished: toPandas at /home/bsuconn/Documents/Fall_2020/STAT_5825/Project/darima-master/run_darima.py:223, took 0.143269 s
20/12/10 15:43:58 INFO SparkContext: Invoking stop() from shutdown hook
20/12/10 15:43:58 INFO SparkUI: Stopped Spark web UI at http://192.168.1.9:4040
20/12/10 15:43:58 INFO YarnClientSchedulerBackend: Interrupting monitor thread
20/12/10 15:43:58 INFO YarnClientSchedulerBackend: Shutting down all executors
20/12/10 15:43:58 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
20/12/10 15:43:58 INFO YarnClientSchedulerBackend: YARN client scheduler backend Stopped
20/12/10 15:43:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/12/10 15:43:58 INFO MemoryStore: MemoryStore cleared
20/12/10 15:43:58 INFO BlockManager: BlockManager stopped
20/12/10 15:43:58 INFO BlockManagerMaster: BlockManagerMaster stopped
20/12/10 15:43:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/12/10 15:43:58 INFO SparkContext: Successfully stopped SparkContext
20/12/10 15:43:58 INFO ShutdownHookManager: Shutdown hook called
20/12/10 15:43:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-8bc0eb3c-92a7-4e21-8a4f-4415f689a7de
20/12/10 15:43:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-96f7a948-2f5e-420e-9537-99ab14a8b509
20/12/10 15:43:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-8bc0eb3c-92a7-4e21-8a4f-4415f689a7de/pyspark-3a80e89b-004a-459e-9da8-140de3fe32f3
